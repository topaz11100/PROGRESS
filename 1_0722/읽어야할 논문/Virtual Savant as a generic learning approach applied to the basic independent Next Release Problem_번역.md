# 기본 독립 다음 릴리스 문제에 적용된 일반 학습 접근 방식으로서의 가상 서번트

**저자:** Renzo Massobrio, Sergio Nesmachnow, Francisco Palomo-Lozano, Bernab´e Dorronsoro

**출처:** Applied Soft Computing, 2021년 5월 1일 제출




## 요약 (Abstract)

이 논문은 가상 서번트 (Virtual Savant, VS)가 정확한 알고리즘으로부터 기본 독립 다음 릴리스 문제 (Next Release Problem)를 빠르고 정확하게 해결하는 방법을 자동으로 학습하는 데 어떻게 사용될 수 있는지를 제시합니다. 다음 릴리스 문제 (NRP)의 이 변형은 본질적으로 0/1 배낭 문제 (Knapsack Problem)이며, VS는 기본 최적화 문제를 해결하는 데 적용됩니다. VS는 기계 학습 (machine learning) 및 휴리스틱 (heuristics)을 기반으로 하는 일반적인 문제 해결 접근 방식으로, 참조 프로그램이 문제 인스턴스에 대한 솔루션을 생성하는 방식을 모방하여 작동합니다. 본질적으로 VS는 참조 알고리즘과 훈련 인스턴스 세트로부터 주어진 문제에 대한 솔루션을 생성하는 방법을 학습하며, 습득된 지식을 사용하여 새로운 문제 인스턴스를 효율적으로 해결할 수 있습니다. 이 논문에서는 정확한 최적화 도구가 참조 알고리즘으로 사용됩니다. 따라서 우리는 최적의 솔루션으로부터 학습하기 위해 VS를 사용하며, 이는 학습 과정에 내재된 근사 오차를 줄이는 데 도움이 됩니다. 우리는 다양한 크기와 난이도의 문제로 구성된 대규모 벤치마크에서 VS의 다섯 가지 버전 (구현하는 휴리스틱이 다름)을 비교합니다. 가장 좋은 VS 구성의 경우, 가장 낮은 계산 복잡성을 가지며, 계산된 솔루션은 최악의 경우 최적값과 1% 미만의 차이를 보입니다. 따라서 VS는 연구 중인 문제를 해결하는 방법을 성공적으로 학습하며, 프로그래머가 문제 도메인에 대한 깊은 지식이나 고도로 전문화된 병렬 프로그래밍 기술을 가질 필요 없이 매우 효율적인 방식으로 이를 수행합니다.

**키워드:** 기본 독립 다음 릴리스 문제, 배낭 문제, 기계 학습, 최적화




## 1. 서론 (Introduction)

요구사항 공학 (Requirements Engineering, RE)은 공학 설계 과정에서 일련의 요구사항을 공식화하고, 문서화하며, 유지 관리하는 과정으로 설명될 수 있습니다 [1]. RE는 많은 공학 분야에서 중요한 학문이며, 특히 소프트웨어 공학 (Software Engineering, SE)에서 시스템을 적절하게 정의하기 위해 소프트웨어 요구사항을 정의하고 분석하는 것이 중요합니다 [2]. 특히 초기 단계 또는 제품의 새 릴리스 시작 시점에 요구사항은 두 그룹으로 분류될 수 있습니다. 한 그룹은 기술적, 전략적 또는 정책 준수 이유로 어떤 제품 버전에서도 존재할 가능성이 높고 없어서는 안 될 핵심 또는 필수 요구사항으로 구성됩니다. 두 번째 그룹은 일반적으로 이해관계자가 요구할 수 있는 다양한 제품 기능을 반영하는 선택적 요구사항으로 구성됩니다. 구현할 선택적 요구사항을 선택하는 것은 RE의 핵심 문제입니다.

다음 릴리스 문제 (Next Release Problem, NRP)는 SE의 관련 문제입니다 [3]. 본질적으로 NRP는 소프트웨어 제품의 다음 릴리스에 포함할 요구사항 또는 기능의 하위 집합을 선택하는 것으로 구성되며, 예상 수익 및 이해관계자 (사용자 또는 고객)가 요구하는 요구사항 및 인식된 관련성과 같은 다른 요소를 고려합니다. 이 선택 문제는 실제적으로 개발 프로세스에 사용할 수 있는 리소스에 의해 제약됩니다. 왜냐하면 요구사항은 구현 비용이 들고 주어진 예산을 초과할 수 없기 때문입니다. 또한 종속성 또는 선행 제약과 같은 요구사항 간의 잠재적 상호 작용도 있습니다. NRP는 현대의 복잡한 소프트웨어 시스템을 개발하고 유지 관리하는 데 관련성이 높은 문제이며, 검색 기반 RE 및 SE 접근 방식이 적용된 가장 인기 있는 문제 중 하나입니다. 검색 기반 접근 방식은 최적화 문제로 공식화된 RE 및 SE 문제를 해결하기 위해 진화 알고리즘 [4]과 같은 휴리스틱 및 메타휴리스틱 검색 방법을 자주 적용합니다.

Bagnall et al. [3]의 선구적인 연구에서 제안된 다양한 NRP 변형 중에서, 기본 독립 NRP는 요구사항 간의 종속성을 고려하지 않으며, 다른 이해관계자를 위한 요구사항의 분리된 집합을 고려하고, 달리 명시되지 않는 한, 최대화할 단일 목적 함수를 고려합니다. 목적 함수는 소프트웨어 제품의 다음 릴리스에 대한 요구사항의 수익과 이해관계자의 선호도를 고려합니다.




사용 가능한 예산을 초과하는 총 비용을 발생시키지 않으면서 총 수익을 극대화하는 것입니다. 더 낮은 추상화 수준에서, 기본 독립 NRP는 고전적인 NP-난해 조합 최적화 문제인 0/1 배낭 문제 (KP)의 특정 변형으로 특징지어질 수 있습니다 [5].

이 논문은 최적화 문제를 해결하는 프로그램으로부터 자동으로 학습할 수 있는 새로운 최적화 방법인 가상 서번트 (VS)를 사용하여 0/1 KP로 모델링된 기본 독립 NRP를 해결하는 것을 제안합니다. VS는 기계 학습 및 병렬 컴퓨팅 기술을 결합하여 블랙박스로 간주되는 참조 알고리즘을 기반으로 주어진 문제를 해결하는 방법을 학습합니다 [6, 7]. 이를 위해 기계 학습 분류기는 참조 알고리즘에 의해 해결된 문제 인스턴스 세트를 사용하여 훈련됩니다. 훈련 단계가 완료되면 VS는 병렬 컴퓨팅 기술을 적용하여 참조 알고리즘보다 새롭고 이전에 알 수 없었던, 심지어 더 큰 문제 인스턴스 (즉, 더 많은 변수를 가진)를 효율적이고 정확하게 해결할 수 있습니다. 여기서는 세 가지 연구 질문이 조사됩니다:

**RQ 1** – VS는 다양한 크기와 난이도의 기본 독립 NRP 인스턴스를 해결할 수 있는가?
**RQ 2** – VS의 각 단계가 전체 계산 결과에 미치는 기여는 무엇인가?
**RQ 3** – VS는 여러 컴퓨팅 리소스를 사용할 때 어떻게 확장되는가?

이 연구는 0/1 KP에 대한 VS 적용에 대한 몇 가지 예비 결과가 제시된 이전 학회 논문 [8]을 크게 확장합니다. 이 연구의 주요 목표는 0/1 KP에 대한 최첨단 알고리즘을 제공하는 것이 아니라, 기계 학습 기술을 사용하여 높은 정확도로 문제를 해결하는 방법을 학습하는 것이 가능하다는 것을 보여주는 것입니다. 이 확장 버전의 주요 기여는 다음과 같습니다:

1. VS의 훈련 단계에 대한 철저한 연구.
2. 다양한 크기와 난이도의 기본 독립 NRP 문제 인스턴스에 대한 VS 결과.
3. 연구 중인 문제 인스턴스에 대한 VS 개선 단계에 대한 다양한 대안 비교.
4. 솔루션을 수정하고 개선하는 새로운 방법 및 그 평가.
5. 복잡성 분석.
6. VS의 병렬 확장성 연구.




이 논문의 나머지 부분은 다음과 같이 구성됩니다. 섹션 2에서는 VS, 대상 문제, 대상 문제에 대한 VS의 설계 및 구현, 그리고 복잡성 분석에 대해 자세히 설명합니다. 이 논문의 주제와 관련된 주요 출판물은 섹션 3에 요약되어 있습니다. 그런 다음, 수행된 실험과 얻은 결과는 섹션 4에서 논의됩니다. 마지막으로, 섹션 5에서는 우리의 결론과 미래 연구의 주요 방향을 제시합니다.

## 2. 기본 독립 NRP를 위한 VS (VS for the basic independent NRP)

이 섹션에서는 VS와 0/1 KP로 모델링된 기본 독립 NRP를 해결하는 데 어떻게 적용될 수 있는지에 대해 보고합니다.

### 2.1. VS 개요 (An overview of VS)

VS는 참조 알고리즘으로부터 주어진 최적화 문제를 대규모 병렬 방식으로 해결하는 방법을 학습하는 것을 목표로 하는 새로운 패러다임입니다 [6, 7]. VS는 서번트 증후군 (savant syndrome)에서 영감을 받았습니다. 서번트 증후군은 심각한 정신 장애를 가진 환자가 정상으로 간주되는 것보다 훨씬 뛰어난 특정 능력을 개발하는 극히 드문 정신 상태입니다 [9].

서번트 증후군 환자 (서번트)는 일반적으로 기억, 빠른 계산 또는 예술적 능력과 관련된 단일 특정 활동에서 뛰어난 능력을 발휘합니다. 서번트의 기저 사고 과정은 연구자들에 의해 아직 완전히 이해되지 않았습니다. 그러나 주요 가설은 서번트가 패턴 인식을 통해 학습한다는 것입니다 [10]. 이 메커니즘을 통해 그들은 기본 원리를 이해하지 않고도 문제를 해결할 수 있습니다. 예를 들어, 일부 환자는 소수가 무엇인지 이해하지 않고도 큰 소수를 열거하거나 소수와 비소수를 구별할 수 있습니다.

서번트 증후군에 비유하여, VS는 기계 학습 기술을 사용하여 주어진 문제를 해결할 수 있는 패턴을 찾는 것을 제안합니다. 훈련은 참조 알고리즘에 의해 구축된 문제 인스턴스 세트와 그 솔루션을 사용하여 지도 학습 방식으로 수행됩니다. 훈련 단계가 완료되면 VS는 추가 재훈련 없이도 이전에 알 수 없었던, 어쩌면 더 큰 문제 인스턴스를 해결하기 위해 참조 알고리즘을 에뮬레이트할 수 있습니다.

VS는 두 단계로 작동합니다: 예측 (prediction), 훈련된 분류기가 주어진 (보이지 않는) 문제 인스턴스에 대한 솔루션을 예측하는 데 사용되는 단계; 그리고 개선 (improvement), 예측된 솔루션이 검색 절차를 사용하여 추가로 정제되는 단계.




품질을 향상시키기 위한 휴리스틱 (heuristics)을 사용합니다. 각 단계는 맵-리듀스 (map-reduce) 접근 방식을 따라 대규모 병렬 방식으로 실행될 수 있습니다. 이를 통해 실행 시간을 단축하고 솔루션 공간을 더 잘 탐색할 수 있습니다. 즉, 사용 가능한 리소스의 양이 많을수록 병렬로 실행할 수 있는 독립적인 프로세스의 수가 많아집니다.

### 2.2. 0/1 KP로서의 기본 독립 NRP (The basic independent NRP as a 0/1 KP)

NRP는 특정 소프트웨어 제품의 다음 릴리스에 포함될 요구사항 또는 기능의 하위 집합을 선택하는 것을 다룹니다. 각 요구사항에는 관련 구현 비용과 예상 수익이 있습니다. 수익은 일반적으로 이해관계자의 선호도와 관련이 있으며, 이해관계자는 특정 요구사항이 존재하도록 요구할 수도 있습니다. 요구사항 간에는 종속성이 있을 수 있습니다. 목표는 총 비용에 대한 예산 한도를 초과하지 않으면서 총 수익을 극대화하는 요구사항을 찾는 것입니다.

문헌에는 NRP 문제로 자주 언급되는 많은 변형이 있습니다. Bagnall et al. [3]의 선구적인 연구에 분류가 나타납니다. 기본 독립 NRP는 가장 간단한 변형이며, 고전적인 NP-난해 조합 최적화 문제인 0/1 KP로 모델링될 수 있습니다 [5]. NRP 문제의 이 변형의 중요성은 상대적인 단순성과 다른 많은 변형 (모든 가능한 변형은 아님)이 이 변형으로 축소되거나 변환될 수 있다는 사실에서 비롯됩니다 [3, 11, 12].

이 문제는 다음과 같이 0/1 KP로 수학적으로 공식화될 수 있습니다. n개의 항목 집합이 주어지고, 각 항목에는 이익 p_k와 가중치 w_k가 있으며, 배낭의 용량 C가 주어질 때, 0/1 KP는 배낭 용량을 초과하지 않으면서 총 이익을 극대화하는 항목의 하위 집합을 찾는 것으로 구성됩니다. 식 1은 정확한 문제 공식화를 보여주며, 여기서 결정 변수 x_k ∈ {0,1}는 해당 항목이 배낭에 포함되는지 여부를 나타냅니다. 배낭 용량은 기본 독립 NRP 공식화에서 예산과 유사하며, 항목은 다음 소프트웨어 릴리스에 포함될 것으로 고려되는 요구사항을 모델링하며, 각 항목에는 관련 비용 (항목의 가중치)과 주어진 수익 (항목의 이익)이 있습니다.

```
arg max (sum_{k=1 to n} p_k * x_k)  subject to  (sum_{k=1 to n} w_k * x_k) <= C
```

위에서 언급했듯이, 문헌에는 더 정교한 NRP 변형이 존재합니다. 예를 들어, 원래의 일반 NRP 공식화에서는 요구사항 간의 종속성이 고려됩니다 [3]. 이러한 변형을 다루는 많은 알고리즘이 있습니다.




인스턴스를 기본 독립 NRP의 하나 또는 여러 인스턴스로 변환하여, 효과적으로 가장 간단한 버전을 사용하여 내부적으로 해결합니다. 결과적으로, 기본 독립 NRP는 더 복잡한 시나리오를 고려할 때에도 관련성이 있습니다.

### 2.3. 설계 (Design)

Figure 1은 0/1 KP에 사용되는 VS의 훈련 과정을 보여줍니다. 문제 인스턴스의 각 항목은 VS의 훈련 단계에서 별도의 관찰로 처리됩니다. 따라서 기계 학습 분류기를 위한 훈련 벡터는 주어진 항목의 가중치와 이익 (화살표 1), 그리고 배낭의 용량 (화살표 2)을 포함합니다. 분류 레이블은 그림의 화살표 3이 나타내는 바와 같이, 참조 알고리즘에 의해 계산된 솔루션에서 항목이 배낭에 포함되는지 여부를 나타내는 이진 값입니다.

```
항목들 배낭
용량
무게 문제 인스턴스:
이익 항목들의 목록과 그들의
무게와 이익, 그리고
배낭 용량

1 2

ML 분류기에 대한 입력:
특징:
ML 분류기 1. 단일 항목의 무게와 이익
2. 배낭 용량

레이블:
3
3. 참조 알고리즘이
항목을 배낭에 포함했는지
여부를 나타내는 0/1

참조 알고리즘의 솔루션
```

**Figure 1.** VS의 훈련 단계 개요.

제안된 학습 방식 덕분에 각 문제 인스턴스는 인스턴스의 항목 수만큼의 관찰을 통해 학습 단계에 기여합니다. 이를 통해 학습 과정에 필요한 참조 솔루션의 수를 크게 줄일 수 있습니다. 이 접근 방식의 또 다른 주요 장점은 기계 학습 분류기가 다른 변수의 할당을 알지 못하고도 각 변수의 할당을 결정할 수 있다는 것입니다.




솔루션은 문제 인스턴스의 항목 수만큼 많은 독립적인 프로세스에 의해 병렬로 구축될 수 있습니다. 각 독립적인 프로세스는 동일한 기계 학습 분류기의 복제일 뿐입니다.

```
항목들
무게 문제 인스턴스:
이익 항목들의 목록과 그들의
배낭
용량 배낭 용량

예측 단계:
ML ML ML ML ML ML
각 항목을 배낭에
포함할 (또는 포함하지 않을)
확률을 예측하는 분류기

각 항목을 포함할 확률
p(1)=1-p(0)

개선 단계:
각 후보 솔루션을 개선하는 것을 목표로 하는
휴리스틱 적용

개선 개선 개선 개선
연산자 연산자 연산자 연산자

최종 솔루션
```

**Figure 2.** 주어진 문제를 해결하기 위한 VS의 예측 및 개선 단계 개요.

기계 학습 분류기를 훈련한 후, VS는 학습에 사용된 것보다 새롭고, 이전에 알 수 없었던, 심지어 더 큰 인스턴스도 처리할 수 있습니다. Figure 2에 설명된 이 과정은 예측 및 개선의 두 단계를 포함합니다. 예측 단계에서 VS는 해결할 알 수 없는 문제 인스턴스를 입력으로 받습니다. 기계 학습 분류기가 각 항목을 개별적으로 고려하여 훈련되었기 때문에, 동일한 분류기의 여러 복사본을 생성하여 풀을 형성하고, 이 풀을 사용하여 새 문제 인스턴스를 분할하고 각 변수에 대한 예측을 병렬로 수행할 수 있습니다. 잠재적으로, 문제 인스턴스의 각 항목은 동일한 분류기의 다른 복사본에 의해 처리될 수 있습니다.




분류기. 각 분류기의 출력은 해당 항목을 배낭에 포함할 확률입니다. 각 항목에 대해 독립적으로 예측이 이루어지는 이 아키텍처는 VS에 높은 수준의 병렬성을 제공합니다. 풀의 각 분류기가 계산한 결과는 단일 벡터로 수집되어 각 항목을 배낭에 포함할 확률을 보유합니다.

개선 단계 (improvement phase) 동안, 예측 단계 후에 구축된 확률 벡터는 다른 후보 솔루션을 생성하는 데 사용됩니다. 이러한 솔루션을 구축하는 여러 가능성이 있습니다. 이 연구에서는 기계 학습 분류기가 보고한 각 항목을 포함할 확률에 따라 무작위 샘플을 수행하는 일반적인 방법을 따릅니다. 각 생성된 솔루션은 개선 연산자 (improvement operator)의 대상이 되며, 이는 더 나은 결과를 얻기 위해 솔루션을 수정하는 것을 목표로 합니다. 이 단계는 예측 단계가 제대로 수행되지 않을 수 있는 특정 문제 인스턴스에서도 중요한 역할을 합니다. 개선 단계 또한 대규모 병렬 처리가 가능합니다. 예를 들어, 사용 가능한 컴퓨팅 리소스당 하나의 후보 솔루션을 생성하고 개선할 수 있습니다. 생성된 솔루션이 실행 불가능할 수 있다는 점, 즉 배낭 용량 제약 조건을 만족하지 못할 수 있다는 점에 유의해야 합니다. 따라서 개선 단계에서는 계산된 솔루션의 실행 가능성을 보장하기 위해 수정 연산자 (correction operator)를 포함해야 합니다. 이 연구에서는 개선 및 수정 연산자에 대한 여러 대안을 고려하며, 이는 다음 섹션에서 설명합니다.

알고리즘 1은 0/1 KP에 적용된 VS 설계의 의사 코드를 보여줍니다. 3행부터 5행까지의 루프는 각 항목의 가중치와 이익, 그리고 배낭 용량을 기반으로 각 항목을 포함할 확률이 예측되는 예측 단계에 해당합니다. 6행부터 9행까지의 루프는 VS의 개선 단계에 해당하며, 예측 단계에서 계산된 확률을 기반으로 후보 솔루션이 생성되고 개선 연산자를 사용하여 정제됩니다. 마지막으로, 가장 잘 생성된 솔루션이 반환됩니다 (10행). 두 루프 모두 병렬화하기 쉽습니다.

### 2.4. 구현 (Implementation)

0/1 KP에 대한 VS의 각 단계에 대한 구현 세부 사항은 다음과 같습니다.

#### 2.4.1. 예측 단계 (Prediction phase)

0/1 KP를 해결하기 위한 VS 구현은 지도 기계 학습 분류기로서 서포트 벡터 머신 (Support Vector Machines, SVMs)을 사용합니다. 훈련 세트는




```
알고리즘 1: 0/1 KP에 적용된 VS.
입력: 인스턴스
확률 벡터 ← []
1
후보 솔루션 ← []
2
각 항목에 대해 인스턴스에서 다음을 수행:
3
확률 벡터[항목] ← 예측(항목.무게, 항목.이익,
4
인스턴스.배낭 용량)
끝
5
i ← 0부터 후보 솔루션.크기-1까지 반복:
6
후보 솔루션[i] ← 솔루션 생성(확률 벡터)
7
개선 연산자(후보 솔루션[i])
8
끝
9
최고(후보 솔루션) 반환
10
```

참조 알고리즘으로 Nemhauser-Ullmann 알고리즘을 사용하여 해결된 문제 인스턴스로 구성되며, 이는 0/1 KP에 대한 정확한 솔루션을 계산합니다 [13, 11]. 우리는 잘 알려진 LIBSVM 프레임워크 [14]에서 제공하는 SVM 구현을 채택했습니다. 이 구현의 특정 포크는 다중 코어 아키텍처에서 실행되도록 조정되어 VS 패러다임에 적합하도록 생성되었습니다 [15]. 벡터를 더 높은 차원 공간으로 매핑하기 위해 방사형 기저 함수 (Radial Basis Function, RBF) 커널이 사용되었습니다.

#### 2.4.2. 개선 단계 (Improvement phase)

개선 단계에 대해 두 가지 다른 제안이 구현되었으며, 다음에서 설명하고 섹션 4에 설명된 실험 평가에서 비교 및 평가됩니다.

**지역 탐색 및 수정 (Local search and corrections).** 개선 단계에 대한 첫 번째 제안된 계획은 각 생성된 솔루션에 간단한 지역 탐색 (Local Search, LS) 휴리스틱을 적용하는 것입니다. 이 LS 연산자는 단순히 후보 솔루션에 무작위 수정을 수행하여 배낭에 있거나 없는 항목을 각각 제외하거나 포함합니다. LS의 각 단계에서 후보 솔루션의 무작위로 선택된 비트가 뒤집히고, 새 솔루션은 점수 할당 함수를 사용하여 평가되며, 개선이 발견되면 LS는 해당 솔루션에서 계속됩니다. 알고리즘 2는 LS를 안내하는 데 사용되는 점수 할당 함수를 설명합니다. 이 함수는 총 가중치 W, 총 이익 P, 그리고 초과 가중치 O = W - C (여기서 C는 배낭 용량)를 가진 솔루션을 고려합니다. W,




P, 그리고 O는 문제 인스턴스의 최소 및 최대 가중치 및 이익 값을 사용하여 스케일링됩니다. 상수 f > 0은 과중량 솔루션에 대한 페널티 계수로 사용되며, m ∈ (0,1)은 LS가 고려할 솔루션의 최대 과중량을 정의하는 데 사용됩니다.

점수 할당 함수는 LS가 용량 제약 조건을 최대 m배까지 초과하는 총 가중치를 가진 실행 불가능한 솔루션을 탐색할 수 있도록 고안되었지만, 검색을 실행 가능한 솔루션으로 유도하기 위해 이러한 솔루션에 페널티를 부과합니다.

```
알고리즘 2: 지역 탐색 중 솔루션에 대한 점수 할당.
입력: 솔루션, 인스턴스
스케일(W, P, O, C, 인스턴스)
1
만약 O ≤ 0이면 P 반환
2
그렇지 않고 O ≤ m·C이면 P −f ·O 반환
3
그렇지 않으면 −O 반환
4
```

LS 연산자가 반환하는 솔루션이 실행 불가능할 수 있으므로, 실행 가능성을 보장하기 위해 수정 연산자를 포함해야 합니다. 두 가지 다른 수정 접근 방식이 고려되었습니다:

1.  **이익에 의한 수정 (Cprofit):** 솔루션의 총 가중치가 배낭 용량보다 크지 않을 때까지 가장 낮은 이익을 가진 항목을 반복적으로 제거합니다.
2.  **가중치에 의한 수정 (Cweight):** 솔루션의 과중량보다 낮지 않은 가중치를 가진 항목을 반복적으로 검색하여 그 중에서 가장 낮은 가중치를 가진 항목을 제거합니다. 이 조건을 만족하는 항목이 없으면 전체적으로 가장 높은 가중치를 가진 항목이 제거됩니다.

**탐욕적 수정 및 개선 (Greedy correction and improvement).** 배낭 문제에 대한 인기 있는 탐욕적 전략에서 영감을 받은 개선 단계에 대한 대안 연산자가 고려되었습니다. 먼저, 후보 솔루션의 총 가중치가 배낭 용량을 초과하는 동안, 실행 불가능한 솔루션을 수정하기 위해 가장 낮은 이익/가중치 비율을 가진 항목이 반복적으로 제거됩니다. 그런 다음, 후보 솔루션의 총 가중치가 배낭 용량 내에 있는 동안 (즉, 배낭에 항목을 추가할 공간이 여전히 있는 동안), 탐욕적 개선 계획은 이익/가중치 비율의 내림차순으로 남은 항목을 하나씩 반복적으로 추가합니다.




### 2.5. 복잡성 분석 (Complexity analysis)

새로운 문제 인스턴스를 해결할 때 VS 알고리즘의 계산 복잡성은 다음에서 분석되는 두 단계 (즉, 예측 및 개선)의 복잡성에 따라 달라집니다.

예측 단계는 새로운 문제 인스턴스의 각 항목에 대해 RBF 커널을 가진 SVM을 정의하는 방정식을 해결하는 것을 포함합니다. 항목을 배낭에 포함할지 여부를 예측하는 것은 O(d · k)의 복잡성을 가지며, 여기서 k는 훈련된 모델의 서포트 벡터 수이고 d는 입력 벡터의 차원입니다. 따라서 이 단계의 총 복잡성은 O(d · k · n)이며, 여기서 d는 특징의 수이고, k는 훈련 샘플 수의 상한선이며1, n은 해결되는 문제 인스턴스의 크기입니다. 섹션 4에 설명된 실험에서 k = 8046이고 d = 3입니다. 왜냐하면 항목 가중치, 항목 이익, 배낭 용량의 세 가지 특징이 있기 때문입니다.

개선 단계는 특정 개선 연산자를 적용하는 것을 포함하므로, 그 복잡성은 적용된 특정 개선 연산자에 따라 달라집니다. 탐욕적 접근 방식 (섹션 4에 보고된 바와 같이 전반적으로 최고의 결과를 달성함)의 경우 절차는 두 단계로 구성됩니다. 첫 번째 단계에서는 용량이 초과되는 한 가장 낮은 이익/가중치 비율을 가진 항목을 배낭에서 반복적으로 제거합니다. 두 번째 단계에서는 용량이 초과되지 않는 한 (즉, 배낭에 항목을 추가할 공간이 여전히 있는 한) 가장 높은 이익/가중치 비율을 가진 항목을 반복적으로 삽입합니다. 이는 밀도 (즉, 각 항목의 이익/가중치 비율)별로 항목 목록을 미리 정렬한 다음, 선형 시간으로 정렬된 목록을 두 번 반복하여 효율적으로 구현됩니다: 항목을 제거하기 위해 왼쪽에서 오른쪽으로, 남은 항목을 포함하기 위해 오른쪽에서 왼쪽으로. 따라서 탐욕적 개선 연산자의 복잡성은 다항 로그 사전 정렬 단계에 의해 지배되며, 최악의 경우 O(n log n)입니다.

전반적으로, VS의 복잡성은 O(d · k · n + n log n)이며, d는 고정된 작은 값으로 가정할 수 있으므로 고정 매개변수 복잡성은 O(max{k · n, n log n})입니다.

1상한선은 각 샘플이 서포트 벡터로 사용되는 극단적인 경우에만 도달합니다.




## 3. 관련 연구 (Related Work)

이 섹션에서는 0/1 KP 및 기본 독립 NRP에 대한 이전 연구 개요와 최적화 문제 해결에 적용된 기계 학습 방법에 대한 간략한 조사를 제시합니다.

### 3.1. 0/1 KP 및 기본 독립 NRP (0/1 KP and the basic independent NRP)

0/1 KP는 운영 연구에서 널리 연구되는 문제입니다. Dantzig [16]은 이 문제를 연구하고 이를 “배낭 문제”라고 불렀으며, 정수 계획법 관점에서 그 중요성을 인식했습니다. 1969년 Nemhauser와 Ullmann [13]은 동적 프로그래밍을 사용하여 0/1 KP를 해결하는 정확한 알고리즘을 제안했습니다. 이 알고리즘은 경영 분야의 잘 알려진 문제인 제약된 예산 내에서 자본을 할당하는 데 적용되었습니다. 기본 자본 할당 문제는 투자 기회 또는 프로젝트를 배낭에 포함할 항목으로, 사용 가능한 투자 예산을 배낭 용량으로 고려하여 0/1 KP로 모델링될 수 있습니다. 각 프로젝트에는 필요한 투자와 예상 투자 수익이 있으며, 이는 0/1 KP 공식화에서 항목의 가중치 및 이익과 유사합니다. 따라서 자본 할당 문제는 주어진 제약된 예산 내에서 투자할 프로젝트 포트폴리오를 찾는 것으로 구성됩니다.

0/1 KP에 대해 풍부한 알고리즘과 기술이 개발되었습니다. Martello와 Toth [17]의 책과 최근에는 Kellerer et al. [5]의 책은 기본 이론과 실제 측면 논의를 포함하여 배낭 관련 문제 및 알고리즘에 대한 권위 있는 자료입니다.

Bagnall et al. [3]은 RE에서 산업적으로 중요한 최적화 문제로 NRP를 소개했습니다. 문제의 여러 버전이 논의되며, 목적 함수는 이해관계자의 만족도를 평가하는 것을 목표로 하고 목표는 다양한 제약 조건에 따라 이를 최대화하는 것입니다. 정확한 알고리즘의 한계를 고려할 때, 근사 알고리즘과 휴리스틱도 사용되었습니다. NRP의 가장 간단한 버전은 우리 연구에서 사용된 기본 독립 NRP입니다. Bagnall et al.은 또한 일부 더 일반적인 버전이 기본 독립 NRP로 어떻게 변환될 수 있는지 논의합니다.

Harman et al. [11]은 0/1 KP로 모델링된 기본 독립 NRP를 연구하고 요구사항 추정의 불확실성이 미치는 영향을 고려하여, 프로젝트에서 요구사항 비용을 추정할 때 부정확성을 다루는 데 도움이 되는 민감도 분석 도구를 제시했습니다. 기본 아이디어는 비용 추정의 작은 편차가 최적값에 큰 영향을 미치는 요구사항을 식별하는 것입니다.




솔루션. 일단 이러한 문제가 되는 요구사항이 식별되면, 의사 결정자는 민감한 요구사항의 추정에 더 많은 자원을 할당할 수 있습니다. 불확실성은 각 원본 인스턴스에 대해 여러 기본 독립 NRP 인스턴스를 생성함으로써 다루어집니다. Nemhauser와 Ullmann [13]의 원본 알고리즘의 최적화된 구현이 0/1 KP 인스턴스를 해결하는 데 사용되었습니다. 이 최적화된 구현은 우리 연구에서도 VS의 훈련 단계에서 참조 알고리즘으로 사용됩니다.

Veerapen et al. [12]은 정수 선형 프로그래밍 (ILP)을 사용하여 단일 및 이중 목적 함수 공식화를 포함한 NRP의 다양한 변형을 해결했습니다. NRP의 일부 변형을 단순화하기 위한 변환 세트가 논의됩니다. 최적화 소프트웨어 CPLEX가 ILP 인스턴스를 해결하는 데 사용되었으며, 이 접근 방식의 성능이 Bagnall의 선구적인 연구 이후 크게 향상되었음이 관찰되었습니다. 이러한 개선은 컴퓨팅 파워의 극적인 증가뿐만 아니라 ILP 솔버의 꾸준한 발전에서도 비롯됩니다. Veerapen et al.이 제안한 접근 방식에서 목표는 합리적인 크기의 인스턴스를 관리할 수 있는 정확한 최적화 방법을 제공하는 것입니다. 문제가 NP-난해이므로, 대규모 문제 인스턴스의 경우 실행 시간이 극적으로 증가할 수 있습니다. 대조적으로, VS는 훈련 단계가 완료되면 빠르고 예측 가능한 실행 시간으로 완전히 확장 가능한 좋은 근사 방법을 제공하는 것을 목표로 합니다.

### 3.2. 최적화 문제를 위한 기계 학습 (Machine learning for optimization problems)

문헌 검토에서 조합 최적화 문제를 해결하기 위해 기계 학습 기술을 적용한 논문은 거의 발견되지 않았습니다.

Vinyals et al.은 순환 신경망 (RNN)을 기반으로 하는 모델인 포인터 네트워크 (Pointer Networks, ptr-nets)를 소개했습니다 [18]. Ptr-nets는 해결된 문제 인스턴스를 관찰하여 훈련되며, VS 패러다임과 유사하게 다양한 크기의 문제 인스턴스를 처리할 수 있습니다. 제안된 접근 방식은 평면 볼록 껍질 찾기, 델로네 삼각 분할 계산, 평면 여행하는 외판원 문제 (TSP) 해결과 같은 세 가지 이산 조합 최적화 문제를 해결할 때 평가됩니다. 실험 결과는 ptr-nets가 훈련 단계에서 본 것보다 더 큰 문제 인스턴스에서 경쟁력 있는 결과를 찾을 수 있음을 보여줍니다.

나중에 Bello et al. [19]은 ptr-nets 아키텍처에서 강화 학습을 사용하여 TSP를 해결할 때 Vinyals et al.의 결과를 능가했으며, 음의 투어 길이를 보상 신호로 사용했습니다. 실험 평가는 최대 100개 도시의 TSP 인스턴스에서 수행되었습니다. 제안된 접근 방식의 다른 최적화 문제에 대한 적용 가능성을 설명하기 위해 저자들은




0/1 KP. 이 문제에 대해 실험 평가는 최대 200개 항목의 인스턴스에서 수행되었습니다. 제안된 접근 방식은 연구된 모든 문제 인스턴스를 최적으로 해결할 수 있었습니다. 우리 논문에서는 항목의 가중치와 이익 간의 다양한 상관 관계를 가진 최대 1500개 항목의 인스턴스에 대해 제안된 VS 프레임워크를 평가합니다.

최근 Hu et al. [20]은 Vinyals et al. [18]이 제안한 모델을 확장하고 이를 0/1 KP와 관련된 최적화 문제인 3차원 빈 패킹 문제 (three-dimensional bin packing problem)를 해결하는 데 적용했습니다. 딥 강화 학습 (deep reinforcement learning) 접근 방식은 빈에 포장할 항목의 순서를 예측하는 데 사용됩니다. 항목이 배치되는 특정 빈 공간과 각 항목의 방향은 휴리스틱 방법으로 계산됩니다. 제안된 접근 방식은 실험 분석 동안 문제에 대한 특정 휴리스틱보다 뛰어난 성능을 보였습니다. 연구된 문제 인스턴스에 대해 기준 휴리스틱보다 평균 5%의 개선이 달성되었습니다. 강화 학습은 또한 Li와 Malik에 의해 제약 없는 연속 최적화 문제에 대한 최적화 도구를 자동으로 생성하는 데 사용됩니다 [21]. 결과 알고리즘은 마지막 반복에서 목적 함수의 기울기에 의해 안내되는 반복 프로세스입니다.

Dai et al.은 최적화 문제를 해결할 때 구조가 거의 변하지 않고 문제 인스턴스만 특정 데이터에서 달라진다는 사실을 활용할 것을 제안했습니다 [22]. 저자들은 강화 학습과 그래프 임베딩을 결합하여 그래프에 대한 최적화 문제를 해결하는 프레임워크를 제안했습니다. 제안된 접근 방식은 탐욕적인 방식으로 솔루션을 구성하고 structure2vec이라는 그래프 임베딩 네트워크를 활용하여 그래프 구조를 학습 과정에 통합합니다. 실험 결과는 제안된 접근 방식이 전체 솔루션을 계산하는 데 그래프 구조가 중요한 문제에 유용하다는 것을 보여줍니다. 연구된 세 가지 그래프 문제에 대한 실제 데이터 세트에 대한 실험 결과도 요약되어 있습니다.

Selsam et al.은 메시지 전달 신경망 (Message Passing Neural Networks, MPNN)을 기반으로 하는 명제 만족 문제 (propositional satisfiability problem, SAT) 해결사인 NeuroSAT을 제안했습니다 [23]. 제안된 접근 방식은 문제 인스턴스의 만족도만을 감독 비트로 사용하여 MPNN을 훈련하는 것에 의존합니다. 실험 평가는 네트워크가 여러 반복 후에 만족도를 예측할 수 있음을 보여줍니다. 클러스터링을 기반으로 하는 사후 절차는 신경망의 활성화에 기반하여 각 변수의 부울 값을 도출하는 데 사용됩니다. 실험 평가는 NeuroSAT이 훈련 중에 사용된 것보다 더 큰 인스턴스를 해결할 수 있음을 보여주었지만, 더 많은 반복을 요구하고 효율성이 크게 떨어졌습니다. 제안된 접근 방식은




NeuroSAT의 광범위한 적용 가능성을 보여주기 위해 SAT 인스턴스로 모델링된 여러 그래프 문제를 해결하는 데 적용되었습니다. NeuroSAT의 훈련 또는 예측 실험에 대한 실행 시간 또는 성능 지표는 보고되지 않았습니다.

최근 두 연구는 스케줄링 문제를 해결하기 위해 강화 학습을 적용했습니다. Waschneck et al.은 Job Shop Scheduling 문제에 Deep Q Network (DQN)를 적용했습니다 [24]. 소규모 공장 시뮬레이션에 대한 실험 분석은 제안된 접근 방식이 전문가가 계산한 것과 유사한 품질의 솔루션을 달성하지만 고전적인 디스패칭 휴리스틱을 능가하지는 못한다는 것을 보여주었습니다. 더 최근에 Wang et al.은 다중 목표 워크플로우 스케줄링 문제를 연구하기 위해 유사한 접근 방식을 적용했습니다 [25]. DQN 강화 학습 모델은 작업 완료 시간과 사용자 비용을 최소화하는 목표로 클라우드 환경에서 컴퓨팅 작업을 스케줄링하는 데 사용됩니다. 실제 데이터를 기반으로 한 문제 인스턴스에 대한 실험 평가는 제안된 접근 방식이 문제에 대한 여러 기준 휴리스틱 및 메타휴리스틱을 능가할 수 있음을 보여주었습니다.

문헌의 일부 연구는 기계 학습을 사용하여 NRP를 다루었습니다. Arau´jo와 Paixa˜o [26]는 NRP를 해결하기 위해 기계 학습과 대화형 유전 알고리즘을 결합한 아키텍처를 제안했습니다. 그들의 제안된 접근 방식에서 기계 학습 모델은 요구사항 엔지니어 선호도를 모델링하는 데 필요한 인간 상호 작용을 대체하는 데 사용됩니다. 목표는 궁극적으로 유전 알고리즘 실행에 필요한 인간 상호 작용을 대체하는 것입니다. 그들의 모델에서 사용자 선호도는 대화형 유전 알고리즘의 첫 번째 반복에서 이루어진 입력을 기반으로 학습됩니다. 기계 학습 모델은 이 논문에서만 제안됩니다. 모델 구현 및 실험 평가는 더 최근 논문 [27]에 보고됩니다. 제안된 접근 방식은 우리 논문에서 제안된 것과 크게 다릅니다. 그들의 접근 방식에서 기본 최적화 문제는 유전 알고리즘을 사용하여 해결됩니다. 즉, 기계 학습은 사용자 선호도를 기반으로 인스턴스의 항목 수익을 예측하는 데만 적용됩니다. 우리 접근 방식에서는 VS가 참조로 정확한 알고리즘을 사용하여 기본 최적화 문제를 해결하는 방법을 학습하는 데 사용됩니다.

VS 패러다임은 Pinel과 Dorronsoro에 의해 도입되었으며, 작업 스케줄링 문제에 적용되었습니다 [6]. 이 연구는 나중에 훈련 단계에서 다른 참조 알고리즘을 평가하고 개선 단계에 다른 절차를 포함함으로써 확장되었습니다 [28, 7]. 또한, VS 패러다임의 병렬 기능은 다중 코어 컴퓨팅 환경에서 평가되었습니다 [29]. 0/1 KP에 대한 VS의 적용은 Massobrio et al. [8]에 의해 처음 연구되었습니다. VS와




조사된 연구들 간의 주요 차이점은 VS가 제공하는 대규모 병렬 기능입니다. VS는 솔루션 벡터의 각 변수를 독립적으로 예측하기 때문에 여러 컴퓨팅 리소스를 효율적으로 사용하고 대규모 병렬 컴퓨팅 아키텍처에 배포될 수 있습니다. 이 논문은 훈련 단계에 대한 더 깊은 연구를 수행하고 성능을 평가하며, 개선 단계에 대한 새로운 전략을 제안함으로써 VS에 대한 이전 연구를 확장합니다.

## 4. 실험 분석 (Experimental analysis)

이 섹션에서는 0/1 KP로 모델링된 기본 독립 NRP에 대한 제안된 VS의 실험 분석을 보고합니다. 실험에 사용된 문제 인스턴스가 설명되고 VS에서 작동하는 각 단계 (훈련, 예측 및 개선)의 결과가 보고되고 논의됩니다.

### 4.1. 문제 인스턴스 (Problem instances)

기본 독립 NRP에 대한 제안된 VS는 문제 인스턴스의 표준 벤치마크를 사용하여 훈련되고 평가되었습니다. 이 인스턴스는 Nemhauser-Ullmann 알고리즘을 사용하여 최적으로 해결되었습니다. 벤치마크는 요구사항의 비용과 수익 간의 다양한 크기와 피어슨 상관 관계를 가진 문제 인스턴스로 구성됩니다. 피어슨 상관 관계는 일반적으로 문제 인스턴스를 해결하는 난이도를 특징짓는 데 적용되는 측정값입니다 [11]. 벤치마크는 총 50개의 데이터 세트를 포함하며, 각 데이터 세트에는 다양한 크기와 피어슨 상관 관계를 가진 300개의 인스턴스가 있습니다. 벤치마크는 공개적으로 사용 가능하며, 카디스 대학교 (University of Ca´diz)의 다음 릴리스 문제 웹사이트 (ucase.uca.es/nrp)에서 다운로드할 수 있습니다.

각 데이터 세트 내에서 인스턴스 크기는 100에서 1500개의 요구사항까지 다양합니다 (단계 크기: 100). 각 인스턴스 크기에 대해 요구사항의 비용과 수익 간의 피어슨 상관 관계는 0.0에서 0.95까지 다양합니다 (단계 크기: 0.05). Figure 3과 Figure 4는 다른 피어슨 상관 관계를 가진 인스턴스에서 비용과 수익 간의 관계의 두 가지 예를 보여줍니다.

벤치마크의 50개 데이터 세트 중 데이터 세트 #1은 VS의 훈련 단계 동안 관찰에 사용되었고, 데이터 세트 #2부터 #5까지는 훈련 세트의 크기를 정의하고 특징 선택에 사용되었으며, 데이터 세트 #6부터 #15까지는 VS 평가에 사용되었습니다. 문제 인스턴스 및 실험 결과는 www.fing.edu.uy/~renzom/vs_nrp.tar.gz에서 확인할 수 있습니다.




```
50000
45000
40000
35000
30000
25000
20000
15000
10000
10000 15000 20000 25000 30000 35000 40000 45000 50000
비용
수익
```

**Figure 3.** 피어슨 상관 관계 = 0.00인 샘플 기본 독립 NRP 인스턴스에서 비용과 수익 간의 관계.

```
60000
50000
40000
30000
20000
10000 15000 20000 25000 30000 35000 40000 45000 50000
비용
수익
```

**Figure 4.** 피어슨 상관 관계 = 0.95인 샘플 기본 독립 NRP 인스턴스에서 비용과 수익 간의 관계.

### 4.2. SVM 훈련 (SVM training)

훈련 실험은 문제의 다양한 특징, 그들 간의 관계, 그리고 훈련 방법의 매개변수 값을 연구하는 데 중점을 둔 점진적 접근 방식을 따라 수행되었습니다. 연구의 목표는 VS의 예측 단계에서 최고의 정확도를 달성할 수 있는 매개변수 구성과 특징 조합을 결정하는 것이었습니다. 다음으로 세 단계 분석이 수행되었습니다.




첫 번째 단계: 입력 특징 연구. 첫 번째 단계에서는 SVM의 입력 벡터에 대해 세 가지 다른 특징 구성이 평가되었습니다.

*   **C1:** 항목 가중치, 항목 이익, 배낭 용량 (3가지 특징).
*   **C2:** 항목 가중치, 항목 이익, 배낭 용량과 인스턴스의 총 항목 수 간의 비율 (3가지 특징).
*   **C3:** 항목 가중치, 항목 이익, 배낭 용량, 인스턴스의 총 항목 수 (4가지 특징).

세 가지 특징 구성을 사용하여 각 데이터 세트에 대한 평균 정확도 (즉, 훈련된 SVM의 최적 솔루션에 대한 정확한 예측 비율)가 평가되었습니다. 결과는 고려된 다른 특징 구성 간에 미미한 차이를 보였으며, 정확도 값은 89.4%에서 89.7% 사이였습니다. 결과적으로, 단순성 때문에 구성 C1이 나머지 실험 분석에 선택되었습니다.

두 번째 단계: 훈련 관찰 수 연구. SVM의 훈련 단계에서 사용된 관찰 수에 대한 연구가 수행되었습니다. 표 1은 훈련 중에 사용된 데이터 세트 1의 관찰 수를 변경할 때의 예측 정확도를 보여줍니다. 데이터 세트 1의 15%로 훈련하면 10%만 사용했을 때보다 예측 정확도가 31% 향상됩니다. 그러나 데이터 세트 1의 15%를 초과하여 훈련 세트 크기를 늘리면 정확도 향상이 미미합니다. 훈련 시간이 더 큰 훈련 세트에서 급격히 증가하므로, 데이터 세트 1의 15%로 훈련된 SVM이 나머지 실험 평가에 사용됩니다.

**표 1:** 다른 훈련 세트 크기에 대한 SVM 정확도.

| 관찰 수 (총계의 %) | 252000 (100%) | 126000 (50%) | 63000 (25%) | 37800 (15%) | 25200 (10%) |
|---|---|---|---|---|---|
| dataset-2 | 89.6% | 89.5% | 89.4% | 89.4% | 58.0% |
| dataset-3 | 89.5% | 89.4% | 89.3% | 89.3% | 57.9% |
| dataset-4 | 89.6% | 89.5% | 89.3% | 89.3% | 58.0% |
| dataset-5 | 89.7% | 89.6% | 89.4% | 89.4% | 58.0% |




세 번째 단계: 매개변수 구성. SVM 및 RBF 커널 매개변수가 구성되었습니다 (각각 매개변수 C 및 γ). 이를 위해 데이터 세트 1에서 무작위로 선택된 5000개의 관찰 세트에 대해 교차 검증 (CV)이 수행되었습니다. 다음 후보 값으로 5겹 CV가 수행되었습니다: C ∈ [2−5,215] 및 γ ∈ [2−15,23] (단계 크기: 22). 결과는 C = 8192 및 γ = 0.5에서 최고의 정확도 값이 계산됨을 나타냈습니다. CV 전후의 평균 정확도 값은 표 2에 보고됩니다. 매개변수 구성 후 데이터 세트 #2부터 #5까지 약 1%의 개선이 달성되었습니다.

**표 2:** 교차 검증을 사용한 매개변수 구성 전후의 평균 정확도.

| | CV 전 | CV 후 |
|---|---|---|
| dataset-2 | 89.4% | 90.4% |
| dataset-3 | 89.3% | 90.5% |
| dataset-4 | 89.3% | 90.5% |
| dataset-5 | 89.4% | 90.5% |

### 4.3. 예측 단계 (Prediction phase)

훈련 단계가 완료된 후, VS는 데이터 세트 #6부터 #15까지의 보이지 않는 문제 인스턴스를 사용하여 평가되었습니다. 실험 평가는 표 3에 요약된 특징, 훈련 크기 및 매개변수의 최적 구성을 사용하여 수행되었습니다.

**표 3:** 실험 평가를 위한 구성.

| 매개변수 | 값 |
|---|---|
| 특징 벡터 | <항목 가중치, 항목 이익, 배낭 용량> |
| 훈련 세트 크기 | 37800 |
| C | 8192 |
| γ | 0.5 |

먼저, 우리는 VS의 예측 단계에 대한 연구에 초점을 맞춥니다. Figure 5의 상자 그림은 SVM이 달성한 정확도를 보여줍니다. 문제 인스턴스는 크기별로 그룹화됩니다. VS의 정확도는 최적 솔루션과 비교했을 때 올바르게 예측된 변수의 백분율로 정의됩니다.




Nemhauser-Ullmann 알고리즘에 의해 제공됩니다. 유사하게, Figure 6은 항목의 가중치/이익 피어슨 상관 관계별로 인스턴스를 그룹화했을 때 달성된 정확도 값을 보여줍니다. 상자의 노치는 샘플 간 중앙값의 변동성을 나타냅니다. 두 상자의 노치가 겹치지 않으면 데이터에 95% 신뢰도로 통계적으로 유의미한 차이가 있음을 의미합니다.

```
1.00
0.95
0.90
0.85
0.80
0.75
100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500
크기
정확도
```

**Figure 5.** 다양한 문제 크기에 따른 최적 솔루션을 예측하는 SVM 정확도.

```
1.00
0.95
0.90
0.85
0.80
0.75
0.0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95
상관 관계
정확도
```

**Figure 6.** 다양한 상관 관계에 따른 최적 솔루션을 예측하는 SVM 정확도.

연구된 모든 문제 크기에 대해 SVM이 달성한 중앙값 정확도는 90% 이상입니다. 또한, 다른 크기의 인스턴스 간에는 유의미한 차이가 발견되지 않습니다. 이는 예측




VS의 예측 방식 때문일 수 있습니다. 여기서 각 항목은 개별적으로 고려됩니다. 가중치/이익 상관 관계별로 인스턴스를 그룹화할 때, 상관 관계가 0.5인 인스턴스가 SVM에 대해 예측하기 가장 간단하며, 중앙값 정확도가 97% 이상입니다. 최악의 경우, 가중치/이익 상관 관계가 0.0일 때도 SVM의 중앙값 정확도는 여전히 80% 이상입니다. 전반적으로, 연구된 모든 문제 인스턴스에 대한 평균 정확도는 92.3%였으며, 표준 편차는 5.3%였습니다. 최악의 예측은 크기 100, 상관 관계 0.0인 인스턴스에서 74.0%의 예측 정확도로 이루어졌습니다. 최상의 예측 정확도는 크기 100, 상관 관계 0.35 및 0.65인 두 인스턴스에서 달성되었으며, 최적 솔루션이 예측되었습니다 (즉, 예측 정확도는 100%였습니다).

두 번째 연구 질문 (RQ 2)에 답하기 위해, VS의 각 단계가 전체 계산 결과에 미치는 기여를 평가해야 합니다. VS의 예측 단계의 기여를 측정하기 위해, 개선 연산자를 적용하기 전에 예측된 솔루션의 품질이 평가되었습니다. 섹션 2.4에서 설명했듯이, 예측된 솔루션은 실행 불가능할 수 있습니다 (즉, 포함된 항목의 가중치 합계가 배낭 용량을 초과할 때). 따라서 어떤 경우에는 솔루션 실행 가능성을 보장하기 위해 수정 체계를 적용해야 합니다. 이 실험에서는 개선 연산자를 적용하지 않고 섹션 4에서 설명된 탐욕적 수정을 적용했습니다. 결과는 연구된 문제 인스턴스의 58% 이상에서 전혀 수정이 필요하지 않았음을 보여줍니다. 평균적으로, 주어진 문제 인스턴스의 항목 중 2.2%만이 솔루션 실행 가능성을 보장하기 위해 수정이 필요했습니다. Figure 7과 Figure 8은 각각 다양한 문제 크기와 상관 관계에 따른 VS의 예측 단계에서 달성된 최적값에 대한 비율을 보여줍니다. 최적값에 대한 비율은 계산된 솔루션의 이익과 최적 솔루션의 이익 간의 몫으로 정의됩니다.

결과는 VS의 예측 단계가 대부분의 문제 인스턴스에서 좋은 품질의 솔루션을 계산할 수 있음을 보여줍니다. 평균적으로, VS의 예측 단계만을 기반으로 계산된 솔루션은 알려진 최적값과 9% 차이가 납니다. 문제 인스턴스를 크기별로 그룹화할 때 솔루션 품질 간에 유의미한 차이는 발견되지 않으며, 예측된 솔루션은 중앙값에서 최적값의 10% 이내입니다. 문제 인스턴스를 상관 관계별로 그룹화할 때, 결과는 SVM 예측이 더 큰 상관 관계를 가진 인스턴스에 대해 더 좋은 품질의 솔루션을 계산할 수 있음을 보여줍니다. 이 결과는 예측 정확도에 대한 이전 분석과 일치합니다.




```
1.0
0.9
0.8
0.7
0.6
100.0 200.0 300.0 400.0 500.0 600.0 700.0 800.0 900.0 1000.0 1100.0 1200.0 1300.0 1400.0 1500.0
크기
최적값 대비 비율
```

**Figure 7.** 다양한 문제 크기에 따른 SVM 예측의 최적값 대비 비율.

```
1.0
0.9
0.8
0.7
0.6
0.0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95
상관 관계
최적값 대비 비율
```

**Figure 8.** 다양한 상관 관계에 따른 SVM 예측의 최적값 대비 비율.

### 4.4. 개선 단계 (Improvement phase)

개선 단계에 대한 다양한 전략을 사용할 때의 실험 결과는 다음과 같습니다.

#### 4.4.1. 수정 및 지역 탐색 (Corrections and local search)

최적값 대비 비율은 VS가 계산한 결과를 평가하는 지표로 사용됩니다. Figure 9와 Figure 10은 이익에 의한 수정 (Cprofit)만 적용했을 때, 가중치에 의한 수정 (Cweight)만 적용했을 때, 지역 탐색 후 이익에 의한 수정 (LS+Cprofit), 그리고 지역 탐색 후 가중치에 의한 수정 (LS+Cweight)을 적용했을 때 달성된 평균 최적값 대비 비율을 보여줍니다.




평균 결과는 크기별 (Figure 9) 및 이익/가중치 상관 관계별 (Figure 10)로 인스턴스를 그룹화하여 제시됩니다. 결과는 각 문제 인스턴스의 30회 독립 실행에 해당합니다. 지역 탐색은 1000단계로 실행되었습니다. 지역 탐색의 평가 함수는 다음 매개변수를 사용했습니다: m = 0.2 및 f = 2. 따라서 LS는 배낭 용량 제약 조건을 최대 20%까지 위반하는 솔루션을 탐색할 수 있습니다.

```
0.96
0.94
0.92
0.90
0.88
200 400 600 800 1000 1200 1400
크기
평균 최적값 대비 비율
```

**Figure 9.** 다양한 문제 크기에 따른 평균 최적값 대비 비율.

```
1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.0 0.2 0.4 0.6 0.8 1.0
상관 관계
평균 최적값 대비 비율
```

**Figure 10.** 다양한 가중치/이익 상관 관계에 따른 평균 최적값 대비 비율.

결과는 VS가 연구된 인스턴스에 대해 정확한 결과를 계산할 수 있음을 보여줍니다. 인스턴스를 크기별로 그룹화할 때, VS가 계산한 솔루션은




평균적으로 최적 솔루션보다 3%만 나쁩니다. 수정 체계만 적용하면 (지역 탐색 없이) VS는 여전히 최적값에서 10% 이내의 정확한 솔루션을 계산할 수 있습니다. 인스턴스를 상관 관계별로 그룹화하면 VS가 0.5 및 0.95 상관 관계를 가진 인스턴스를 최적으로 해결할 수 있다는 점이 특히 흥미롭습니다. 평균적으로 VS는 모든 상관 관계에 대해 LS+Cprofit 및 LS+Cweight를 사용할 때 알려진 최적값과 각각 3.15% 및 3.20% 차이가 납니다. 마지막으로, 지역 탐색이 0.5에서 1.0 사이의 상관 관계에 대해 VS가 예측한 솔루션의 품질에 미치는 영향이 낮다는 점 (일부 경우 약간 부정적)에 주목할 가치가 있습니다.

#### 4.4.2. 탐욕적 수정 및 개선 (Greedy correction and improvement)

마지막으로, 탐욕적 수정 및 개선을 사용할 때 VS가 달성한 결과가 제시됩니다. Figure 11은 크기별로 인스턴스를 그룹화했을 때 달성된 최적값 대비 비율을 보여줍니다. 유사하게, Figure 12는 항목의 가중치/이익 상관 관계별로 인스턴스를 그룹화했을 때 계산된 결과를 보여줍니다.

```
1.000
0.999
0.998
0.997
0.996
0.995
0.994
100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500
크기
최적값 대비 비율
```

**Figure 11.** 탐욕적 수정 및 개선을 사용한 다양한 문제 크기에 따른 평균 최적값 대비 비율.

탐욕적 및 수정 개선을 사용할 때 달성된 결과는 연구 중인 모든 인스턴스에서 최적값의 1% 이내입니다 (이 섹션의 비교에서는 적합도 값을 고려합니다). 평균적으로 계산된 결과는 최적값에서 0.04% 이내입니다. 최악의 경우, 크기 100, 상관 관계 0.7인 인스턴스의 경우 VS가 계산한 솔루션은 알려진 최적값과 0.66%만 차이가 납니다. 또한, 연구된 모든 문제 인스턴스의 5.5%에 대해 최적 솔루션이 계산되었습니다. VS는




```
1.000
0.999
0.998
0.997
0.996
0.995
0.994
0.0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95
상관 관계
최적값 대비 비율
```

**Figure 12.** 탐욕적 수정 및 개선을 사용한 다양한 가중치/이익 상관 관계에 따른 평균 최적값 대비 비율.

모든 크기와 상관 관계의 인스턴스를 최적으로 해결합니다. 크기 100, 상관 관계 0.40인 인스턴스 그룹은 최적으로 해결된 인스턴스 수가 가장 많습니다. 크기별로 인스턴스를 볼 때 VS는 더 큰 인스턴스에서 더 잘 수행됩니다. 중앙값 최적값 대비 비율은 연구된 모든 문제 크기에 대해 알려진 최적값에서 0.2% 미만으로 차이가 납니다. 이익/가중치 상관 관계별로 그룹화할 때 문제 인스턴스 간에 유의미한 차이는 발견되지 않습니다. 이 수정 및 개선 체계는 0/1 KP에 대한 잘 알려진 탐욕적 휴리스틱을 기반으로 하므로, 이전에 제시된 LS 및 수정과 달리 VS에 귀중한 도메인별 정보를 포함한다는 점에 주목할 가치가 있습니다. 이러한 결과는 VS가 다양한 크기와 난이도의 문제 인스턴스를 정확하게 해결할 수 있음을 보여주면서 첫 번째 연구 질문 (RQ 1)에 긍정적으로 답합니다.

두 번째 연구 질문 (RQ 2)을 완전히 다루기 위해, 우리는 VS의 예측 단계의 기여를 평가해야 합니다. 이를 위해 우리는 무작위로 생성된 초기 솔루션에 대해 전반적으로 최고의 결과를 달성한 탐욕적 수정 및 개선 연산자를 적용했습니다. 이 실험의 목표는 예측 단계가 좋은 품질의 초기 솔루션을 계산하는 데 중요한 역할을 하며, 이 솔루션은 탐욕적 휴리스틱을 사용하여 개선될 수 있음을 보여주는 것이었습니다. Figure 13과 Figure 14는 각각 다양한 크기와 상관 관계를 가진 문제 인스턴스에서 무작위로 생성된 솔루션에 탐욕적 수정 및 개선을 적용했을 때 달성된 최적값 대비 비율을 보여줍니다.

무작위로 생성된 솔루션에서 시작했을 때 달성된 결과는




```
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
100.0 200.0 300.0 400.0 500.0 600.0 700.0 800.0 900.0 1000.0 1100.0 1200.0 1300.0 1400.0 1500.0
크기
최적값 대비 비율
```

**Figure 13.** 무작위 솔루션에서 시작하여 탐욕적 수정 및 개선을 사용한 다양한 문제 크기에 따른 평균 최적값 대비 비율.

```
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
0.0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95
상관 관계
최적값 대비 비율
```

**Figure 14.** 무작위 솔루션에서 시작하여 탐욕적 수정 및 개선을 사용한 다양한 가중치/이익 상관 관계에 따른 평균 최적값 대비 비율.

평균적으로 최적값에서 20% 떨어져 있습니다. Figure 11과 Figure 12에 보고된 결과와 이 결과를 비교할 때 VS의 두 단계의 중요성을 알 수 있습니다.

### 4.5. VS의 병렬 처리 (Parallelism in VS)

섹션 2.4에서 설명했듯이, VS의 워크플로우는 대규모 병렬 처리를 허용합니다. 다음 실험은 마지막 연구 질문 (RQ 3)에 답하기 위해 매우 큰 문제 인스턴스를 해결할 때 VS의 실행 시간과 병렬 기능을 특성화하기 위해 수행되었습니다. 한 세트의




100,000개에서 1,000,000개의 요구사항을 가진 인스턴스로 구성된 문제 인스턴스 세트가 생성되었습니다. 각 문제 크기에 대해 100,000단계 크기를 고려하여 4개의 인스턴스가 생성되었습니다. 이 인스턴스는 Xeon Phi 다중 코어 컴퓨팅 플랫폼에서 제안된 VS 접근 방식을 사용하여 해결되었습니다.

Figure 15는 스레드 수를 변경할 때 VS의 실행 시간을 보여줍니다. 각 상자 그림은 주어진 문제 크기의 네 가지 인스턴스에 대한 실행 시간을 보여줍니다. 결과는 Figure 16에 요약되어 있으며, 사용된 스레드 수를 변경할 때 모든 인스턴스에서 달성된 속도 향상을 집계합니다. 속도 향상은 t_1 / t_n으로 정의되며, 여기서 t_1은 하나의 처리 장치만 사용할 때의 실행 시간이고 t_n은 n개의 스레드를 생성할 때의 실행 시간에 해당합니다. 유사하게, Figure 17은 사용된 스레드 수로 나눈 속도 향상과 동일한 효율성을 보여줍니다. 마지막으로, Figure 18은 64개 코어를 사용할 때 문제 인스턴스 크기에 대한 실행 시간을 보여줍니다 (다른 코어 수에 대해서도 유사한 결과가 얻어졌습니다).

결과는 연구된 모든 인스턴스에서 하나 이상의 스레드를 사용할 때 좋은 실행 시간 개선이 달성됨을 보여줍니다. 그러나 64개 이상의 코어를 사용할 때 실행 시간 개선이 중단되며, 더 많은 스레드를 사용할 때 상당한 부정적인 영향이 나타날 수 있습니다. 이는 Xeon Phi가 68개의 물리적 코어를 가지고 있기 때문으로 설명될 수 있습니다. 따라서 더 많은 스레드를 사용할 때 일부 CPU 리소스가 스레드 간에 공유되어 상당한 오버헤드가 발생합니다. Figure 18의 결과는 VS의 실행 시간이 문제 인스턴스 크기에 따라 선형적으로 확장됨을 보여줍니다. 이러한 결과는 VS가 여러 컴퓨팅 리소스를 사용할 때 확장할 수 있음을 보여주며, 우리의 최종 연구 질문 (RQ 3)에 답합니다.

## 5. 결론 및 향후 연구 (Conclusions and future work)

이 논문은 VS 패러다임이 요구사항 공학 (RE)에서 복잡한 문제를 효율적으로 해결하는 데 어떻게 사용될 수 있는지를 제시합니다. VS는 기계 학습 기술을 사용하여 참조 알고리즘으로부터 주어진 문제를 해결하는 방법을 학습하는 새로운 최적화 방법입니다. 이 과정은 훈련, 예측 및 개선의 세 단계로 구성되며, 대규모 병렬 처리가 가능합니다. 참조 알고리즘은 무작위로 선택된 매개변수화된 인스턴스에 대한 솔루션을 제공하기 위해 실행되며, 인스턴스-솔루션 쌍은 VS를 훈련하는 데 사용됩니다. VS의 주요 장점은 다음과 같습니다:

i) 참조 알고리즘으로는 처리할 수 없는 더 큰 인스턴스를 해결할 수 있습니다.
ii) 대규모 병렬 처리가 가능합니다.
iii) 유연합니다.




```
Figure 15: 다양한 스레드 수에 따른 실행 시간.
```




```
Figure 16: 연구된 모든 인스턴스에서 다양한 스레드 수에 따른 평균 속도 향상.
Figure 17: 연구된 모든 인스턴스에서 다양한 스레드 수에 따른 평균 효율성.
Figure 18: 64개 코어를 사용하여 연구된 모든 인스턴스에서 다양한 문제 크기에 따른 평균 실행 시간.
```




예측 단계에 사용되는 특정 분류기와 개선 단계에 사용되는 연산자에 대해. VS의 주요 과제는 훈련 단계에서 문제를 효과적으로 분해하고 예측 중에 최고의 정확도를 달성할 수 있는 문제 특징을 선택하는 데 있습니다.

이 논문에서는 VS가 기본 독립 다음 릴리스 문제에 적용되었으며, 이는 0/1 배낭 문제 (KP)로 재구성될 수 있습니다. VS의 훈련 및 예측 단계에 대한 철저한 연구가 제시되었고, 고려 중인 문제에 대해 VS의 개선 단계에 대한 다섯 가지 다른 변형이 분석되었습니다.

실험 평가는 다양한 크기와 상관 관계를 가진 문제 인스턴스의 공개적으로 사용 가능한 벤치마크를 사용하여 수행되었습니다. 항목의 이익과 가중치 간의 상관 관계는 Nemhauser-Ullmann 알고리즘에 대한 인스턴스 난이도 측정값이며, 상관 관계가 높을수록 알고리즘의 효율성이 저하됩니다. Nemhauser-Ullmann 알고리즘은 정확한 방법이며, 우리는 이 연구에서 이를 참조 알고리즘으로 채택합니다. 따라서 우리는 VS를 사용하여 문제에 대한 최적 솔루션을 생성하는 방법을 학습합니다.

우리는 먼저 문제를 정확하게 해결하기 위해 필요한 훈련 세트 크기에 대한 연구를 수행했습니다. 우리는 데이터 세트 1 (사용 가능한 50개 데이터 세트 중)에서 10%, 15%, 25%, 50%, 100%의 관찰 사용을 고려했습니다. 연구를 통해 데이터 세트의 모든 인스턴스의 15%로 구성된 훈련 세트가 거의 최적의 결과를 생성하기에 충분하다는 결론을 내렸습니다. 그 비율을 넘어서는 경우 미미한 개선만 관찰되었습니다. 보이지 않는 인스턴스에 대한 예측 단계의 성능만 고려할 때, VS는 인스턴스를 크기별로 그룹화했을 때 90% 이상의 중앙값 정확도로 정확한 솔루션을 예측할 수 있었고, 이익/가중치 상관 관계별로 그룹화했을 때 80% 이상의 중앙값 정확도로 예측할 수 있었습니다.

VS의 개선 단계는 예측 단계에서 생성된 솔루션을 더욱 정제하는 데 도움이 됩니다. 실험 결과는 VS가 매우 정확한 솔루션을 계산할 수 있음을 보여줍니다. 이 연구에서 연구된 다섯 가지 버전 중에서 가장 간단한 변형 (요소의 이익/가중치 비율을 기반으로 솔루션을 먼저 수정하고 개선하는 탐욕적 메커니즘)이 최고의 결과를 달성했습니다. 이 탐욕적 메커니즘을 구현하는 VS 버전이 계산한 솔루션은 적합도 값에 따라 최악의 경우 최적값에서 1% 이내입니다. 또한, VS는 많은 경우에 최적 솔루션을 생성할 수 있었고, 보고된 적합도 값의 중앙값은 참조 알고리즘이 계산한 최적값에서 0.2% 이상 벗어나지 않습니다. 흥미롭게도 참조 알고리즘에 어려운 인스턴스가 반드시




VS가 해결하기 어려운 것은 아닙니다.

마지막으로, 우리는 Xeon Phi 다중 코어 컴퓨팅 인프라에서 매우 큰 문제 인스턴스를 해결할 때 VS의 확장성을 평가했습니다. 실험 결과는 VS가 여러 처리 장치의 가용성을 활용하여 실행 시간을 크게 줄일 수 있음을 보여주었습니다. 사용된 스레드 수가 플랫폼의 물리적 코어 수를 초과하는 지점까지 상당한 성능 향상이 관찰됩니다. 이 시점에서 컴퓨팅 리소스의 공유는 VS의 성능에 해로워집니다.

향후 연구로, 우리는 0/1 KP의 가장 어려운 알려진 인스턴스에 대한 VS 성능 분석과 다른 제약 조건을 가진 NRP의 더 어려운 변형을 다루는 연구를 확장하는 것이 매우 흥미로울 것이라고 생각합니다. 또한, 다양한 컴퓨팅 환경 (예: 다중 및 멀티 코어 아키텍처, 클러스터, 그리드)에 대한 VS의 적응성을 가까운 미래에 분석해야 합니다. 더욱이, 최첨단 도구에 대해 매우 경쟁력 있는 도구를 설계하기 위해 문제 지식을 활용하는 특정 휴리스틱으로 VS의 개선 단계를 향상시킬 수 있습니다. VS 프레임워크와 관련하여, 우리는 예측 단계에 다른 기계 학습 분류기를 사용할 때 그 성능을 평가할 것입니다. 또한, 우리는 속성 선택 방법을 VS 모델에 포함시킬 계획이며, 이는 많은 특징을 가진 문제에서 특히 관련성이 있을 수 있습니다. 마지막으로, 우리는 VS 패러다임을 다른 다양한 최적화 문제에 적용하는 작업을 할 것입니다. 특히, 우리는 다양한 변수 간의 종속성을 포함하는 그래프에 대한 최적화 문제를 모델링하는 데 관심이 있습니다.

**감사의 글 (Acknowledgements)**

R. Massobrio와 S. Nesmachnow의 연구는 우루과이 ANII와 PEDECIBA의 부분적인 지원을 받았습니다. R. Massobrio는 스페인 Fundacio´n Carolina에 감사드립니다. F. Palomo-Lozano의 연구는 스페인 과학, 혁신 및 대학부의 프로젝트 RTI2018-093608-B-C33 (FAME) 및 RED2018-102472-T (SEBASENet 2.0)의 부분적인 지원을 받았습니다. B. Dorronsoro의 연구는 스페인 과학, 혁신 및 대학부의 프로젝트 RED2018-102472-T (SEBASENet 2.0), 스페인 과학, 혁신 및 대학부 및 ERDF의 계약 RTI2018-100754-B-I00 (iSUNproject), 그리고 프로젝트 FEDER-UCA18-108393 (OPTIMALE)에 따라 ERDF의 지원을 받았습니다.



