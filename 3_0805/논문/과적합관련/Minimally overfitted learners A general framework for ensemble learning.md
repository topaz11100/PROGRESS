**"Minimally overfitted learners: A general framework for ensemble learning"**
---

### 초록 (Abstract)

기계학습(Machine Learning, ML) 알고리즘의 조합은 단일 알고리즘보다 더 강력한 예측기를 구축하기 위한 해결책이다. 하지만 일부 접근법은 **안정적이지 않은(unstable)** 알고리즘을 결합하는 것이 **안정적인(stable)** 알고리즘을 결합하는 것보다 더 나은 결과를 제공한다고 제안한다. 예를 들어, **재표본화(re-sampling)** 기법에 기반한 **생성 앙상블(Generative ensemble)** 은, 불안정한 기본 학습기(base learner)의 정보를 융합함으로써 높은 성능을 보여주었다. **랜덤 포레스트(Random Forest)** 와 **그래디언트 부스팅(Gradient Boosting)** 은 의사결정나무(Decision Tree)를 결합하여 단일 트리보다 더 나은 예측을 제공하는 대표적인 예시이다. 하지만, 안정적인 알고리즘을 조합하여 이와 같은 성공적인 결과를 얻은 사례는 거의 없다.

본 논문은 **제한 학습기(limited learner)** 라는 개념과, **최소 과적합 앙상블(Minimally Overfitted Ensemble, MOE)** 이라는 새로운 일반화된 앙상블 프레임워크를 제안한다. MOE는 재표본화 기반의 앙상블 방식으로, 약간 과적합된 학습기(slightly overfitted learner)를 구성하는 방식이다. 제안된 프레임워크는 **가중 랜덤 부트스트랩(Weighted RAndom Bootstrap, WRAB)** 이라는 샘플링 기법을 통해, 안정적인 알고리즘에서도 필요한 다양성(diversity)을 확보하여 안정적, 불안정한 알고리즘 모두에서 잘 작동한다.

이 프레임워크의 하이퍼파라미터 분석은 인공 데이터에 대해 수행되었고, 또한 실제 데이터셋을 이용해 기존의 잘 알려진 ML 방법들과 성능을 비교하였다. 실험 결과는 MOE 프레임워크가 안정적 및 불안정한 기본 알고리즘 모두에서 성공적으로 작동하며, 대부분의 경우 단일 ML 모델이나 기존 앙상블 기법보다 예측 성능이 향상됨을 확인하였다.

---

### 1. 서론 (Introduction)

기계학습(Machine Learning, ML)은 과거 데이터를 학습함으로써 예측을 수행하는 알고리즘으로 구성된 인공지능(Artificial Intelligence)의 한 분야이다. 이러한 알고리즘들은 새로운 데이터에 대한 추론을 수행하는 모델(model)을 구현한다. 이러한 모델에서 중요한 목표 중 하나는 새로운 데이터에 대한 오류(error)를 가능한 한 낮추는 것이다. 이 오류는 **일반화 오류(generalization error)** 라고 하며, 이는 **감소 가능한 오류(reducible error)** 와 **감소 불가능한 오류(irreducible error)** 라는 두 종류의 오류로 분해될 수 있다. 감소 가능한 오류는 회피할 수 있지만, 감소 불가능한 오류는 항상 존재하게 된다. 따라서 일반화 오류는 감소 가능한 오류를 줄임으로써 낮출 수 있다.

감소 가능한 오류는 다시 두 요소로 분해할 수 있다: **바이어스(Bias)** 와 **분산(Variance)** 오류이다. 바이어스는 모델의 예측값과 실제 값 사이의 차이를 의미하며, 분산은 모델이 서로 다른 학습 데이터로 훈련되었을 때 예측의 변화 정도를 의미한다. 바이어스와 분산 사이에는 상호 보완 관계(trade-off)가 존재하는데, 하나가 증가하면 다른 하나는 감소하는 경향이 있다. 이러한 현상은 바이어스가 높을 때 **과소적합(underfitting)** 이 발생하고, 분산이 높을 때 **과적합(overfitting)** 이 발생할 때 더욱 명확해진다. 하지만, 분류(classification) 문제에 대해 바이어스-분산 분해를 정량적으로 평가하는 것은, 특히 앙상블(ensemble) 방법에서는 단순하지 않다\[1].

기계학습 모델을 조정할 때의 목표는 낮은 일반화 오류를 달성하는 것이다. 따라서 모델은 일반적으로 과적합과 과소적합 사이의 중간, 흔히 **적절한 적합(well-fitted)** 상태에 위치하게 된다. 과적합에는 여러 수준이 존재하며, 강하게 과적합된 상태에서부터 적절하게 적합된 상태까지 다양하다. 과소적합도 마찬가지이다. 이 두 극단적인 상태는 모두 바람직하지 않은 모델을 만든다. 그림 1은 잘 알려진 반달 모양 데이터셋(half-moons dataset)에 대해 다양한 적합 수준을 시각적으로 보여준다.

이상적인 적절히 적합된 기계학습 모델은 학습 집합(training set)과 테스트 집합(test set)에서 동일한 오류를 가지며, 나아가 감소 불가능한 오류와도 일치한다. 실제로는 학습 오류와 테스트 오류가 모두 작고 서로 비슷한 것이 바람직하다. 한편, 학습 오류가 테스트 오류보다 훨씬 작다면 **과적합(overfitting)** 현상이 나타났다고 할 수 있다. 반대로, 학습 오류와 테스트 오류가 모두 크다면 **과소적합(underfitting)** 이라고 할 수 있다. 바람직한 기계학습 모델은 이 두 시나리오 사이에서 균형을 찾는다.

**앙상블(ensemble)** 은 하나의 모델이 아닌 여러 개의 기계학습 모델(단일 학습기, single learner)을 결합하여 사용하는 기법이다. 가장 잘 알려진 앙상블 기법은 **배깅(Bootstrap aggregating, Bagging)** \[2]과 **부스팅(Boosting)** \[3]이다. 일반적으로 앙상블 기반 방법은 단일(그리고 아마도 더 복잡한) 모델보다 성능이 더 우수하다. 배깅과 부스팅에서 이러한 성능 향상의 주요 이유는 단일 학습기 간의 **다양성(diversity)** 때문이다. 이 다양성은 학습 집합을 변형함으로써 얻어진다. 배깅에서는, 각 단일 학습기를 서로 다른 부트스트랩 샘플(bootstrap sample)을 통해 훈련시키고, 예측은 투표 방식으로 결합한다. 부스팅 기반 앙상블에서는, 각 학습기의 오류에 기반하여 학습 샘플에 가중치를 부여하는 방식으로 다양성을 얻는다. 부스팅에서 단일 학습기는 **약한 학습기(weak learner)** 라고 불리며, 이는 무작위 추정보다 약간 더 나은 예측을 제공하는 모델을 의미한다\[4].

바이어스와 분산의 관점에서 보면, 배깅은 주로 분산을 줄이는 데 중점을 두고, 부스팅은 초기에는 바이어스를 줄이고 이후에는 분산을 줄인다.

---

### 2. 생성 앙상블 (Generative ensembles)

기계학습(Machine Learning, ML) 문헌에는 다양한 조합 방식(combination scheme) 및 앙상블(ensemble) 기법들이 존재한다. 이러한 기법들은 선택된 기준에 따라 여러 방식으로 분류될 수 있다. 본 논문에서는 단순화를 위해 \[11,12]에서 제안된 앙상블 분류체계(taxonomy)를 따른다. 이 분류체계는 두 가지 주요 수준으로 나뉜다: **비생성 앙상블(Non-generative ensemble)** 과 **생성 앙상블(Generative ensemble)** 이다. 이 두 수준의 차이는 생성(generation)과 결합(combination) 방식 중 어느 쪽에 중점을 두는가에 따라 결정된다.

**비생성 앙상블(Non-generative ensemble)** 은 기본 학습기(base learner)들의 결합 방식에 중점을 둔다. 따라서 각 학습기는 높은 성능을 달성하도록 사전에 훈련된다. 이러한 유형의 앙상블에는 다음과 같은 예들이 있다: 다수결 투표(majority voting) 방식으로 예측을 생성하는 방법들\[13,14], 베이지안 결합(Bayesian combination) 방식으로 확률 예측값을 조합하는 방법들\[15,16], 가장 적절한 기본 학습기 하위집합을 선택하는 방식\[17] 등이 있다. 이 모든 예에서 핵심은 학습기를 어떻게 결합하느냐에 초점이 맞춰져 있다\[18]. 비생성 앙상블은 적절한 학습기 정보를 결합함으로써\[19], SVM(Support Vector Machine)\[20]이나 결정 트리(Decision Tree, DT)\[21]와 같은 단일 기법보다 더 나은 성능을 보인다는 것이 입증되었다. 특히 교차 도메인 협업 필터링(cross-domain collaborative filtering)과 같은 특정 문제에서 그러하다.

**생성 앙상블(Generative ensemble)** 은 각 기본 학습기를 구성할 때 학습 집합(learning set)이나 기본 알고리즘(base algorithm)에 변형(perturbation)을 가하여 다양한 학습기들을 생성하는 데 초점을 둔다. 즉, 개별 결과를 어떻게 조합할 것인가보다는, 기본 학습기를 어떻게 생성할 것인가에 더 중점을 둔다. 생성 앙상블의 예로는 재표본화 방법(re-sampling methods)\[2,3], 특성 선택(feature selection)\[22], 전문가 혼합(Mixture of Experts)\[23], 고도의 무작위화(highly randomized methods)\[5,24] 등이 있다. 이들 기법은 모두 기본 학습기 사이의 다양성(diversity)을 확보하도록 설계되어 있다.

또한, 생성 앙상블이 단일 학습기보다 우수한 성능을 발휘하기 위한 필요충분조건은 다음 두 가지이다:

1. 개별 학습기가 **정확도(accuracy)** 가 높아야 하며 (즉, 무작위보다 좋은 성능),
2. 학습기 간에 **다양성(diversity)** 이 있어야 한다\[25].

가장 널리 알려진 생성 앙상블은 **배깅(Bagging)** 과 **부스팅(Boosting)** 이다. 이들은 수년 동안 분류(classification)와 회귀(regression) 문제 모두에서 널리 연구되고 활용되어 왔다\[26,27]. 부스팅 기반 앙상블에는 **AdaBoost(Adaptive Boosting)** \[28], **LightGBM** \[29], **XGBoost(eXtreme Gradient Boosting)** \[6] 등이 있으며, 배깅 기반 앙상블에서는 **랜덤 포레스트(Random Forest, RF)** \[5]가 대표적인 선택이다. 이 모든 방법은 공통적으로 재표본화 기반이며, 기본 학습기로 **결정 트리(Decision Tree, DT)** 를 사용한다. DT의 주요 장점은 이상치(outlier)와 잡음(noise)에 강하고, 비선형 패턴을 포착할 수 있다는 것이다. 반면, DT는 불안정하며(overfitting 성향이 강하고), 자주 과적합되는 경향이 있다. 그러나 이러한 단점들조차도 DT를 생성 앙상블에서 기본 학습기로 선택하게 만드는 이유가 된다\[30].

부스팅 기반 방법에서는 하이퍼파라미터가 성능에 매우 큰 영향을 미친다. 반면, RF는 대부분의 구현에서 기본 설정만으로도 좋은 정확도를 제공하며, 추정기 수나 각 트리에 포함되는 특성 수 등만 살짝 조정하면 된다. 이러한 RF의 장점 때문에, 안정적인 기본 학습기를 사용하는 배깅 방식의 변형들도 연구되고 있다. 예를 들어 \[31]에서는 SVM 앙상블을 사용하였고, 이 경우 선형 커널(linear kernel)이 가우시안 커널(Gaussian kernel)보다 더 불안정하므로 더 나은 성능을 보였다. 다른 접근법들은 언더샘플링(under-sampling) 및 오버샘플링(over-sampling) 기법을 통해 학습 데이터를 변형하여 성능을 향상시켰다\[32,33]. 이러한 샘플링 기법은 베이지안 신경망(Bayesian Neural Networks)을 기본 학습기로 사용하는 앙상블에도 적용 가능하다\[34]. 이 경우에는 전통적인 다양성 확보 및 데이터 재균형화(rebalancing) 기법들이 함께 작동하여 성능을 향상시킨다.

문헌에서는 부스팅과 배깅 외에도 **Wagging(Weight Aggregation)** \[9]과 같은 다양한 대안들이 존재한다. Wagging은 각 복제본(replica)에 대해 가중치 벡터에 가우시안 잡음을 추가하여 데이터셋을 변형하는 방식이다. 그러나 Wagging 기반 앙상블은 배깅과 성능이 유사하며\[9], 노이즈 분포에 대한 추가 고려가 필요하므로 모델의 복잡도가 증가한다. 최근에는 안정적인 모델을 조합하기 위해 새로운 배깅 기반 샘플링 기법들이 제안되었지만, 대부분 특정 알고리즘의 특성을 전제로 하기 때문에 일반적으로 적용하기는 어렵다\[35]. 따라서 k-최근접 이웃(k-Nearest Neighbor, kNN)이나 SVM과 같은 조합이 어려운(stable) 학습기들도 효과적인 앙상블로 만들 수 있도록 다양성을 확보하는 새로운 기법 개발이 필요하다.

---

### 3. 제한 학습기 (Limited learners)

이 절에서는 **제한 학습기(limited learner)** 의 개념을 소개한다. 제한 학습기는 자신이 훈련된 샘플에 대해 과적합(overfit)하지만, 새로운 샘플에 대해서도 충분히 좋은 예측을 수행하는 학습기이다.

학습 집합 $L = \{(x_i, y_i) : i = 1, 2, ..., n\}$ 을 고려하자. 여기서 $x_i \in \mathbb{R}^r$ (r은 양의 정수), $y_i \in \{-1, 1\}$ 이다. 샘플링 기법 $S$ (복원 추출 또는 비복원 추출)을 하나 가정하자. 이 샘플링을 통해 얻은 k번째 샘플을 다음과 같이 나타낸다:

$$
L^{(S)}_k = \{(x'_i, y'_i) : i = 1, 2, ..., m\}, \quad m \leq n,\ x'_i \in \mathbb{R}^{\leq r}
$$

샘플링이 특성(feature)에 대해 이루어진 경우, 투영 함수 $\phi : \mathbb{R}^r \rightarrow \mathbb{R}^{\leq r}$ 가 존재하여 $\phi(x_i) \mapsto x'_i$ 이며, $(x'_i, y'_i) \in L^{(S)}_k$ 이고 $(x_i, y_i) \in L$ 이다.

이제 이 샘플 $L^{(S)}_k$ 을 기반으로 학습된 학습기를 $f_k : \mathbb{R}^{\leq r} \rightarrow \{-1, 1\}$ 라고 하자. 이는 서젝티브 함수(surjective function)로, $f_k(x'_i) = y'_i$ 를 만족한다. 테스트는 $T \subseteq L - L^{(S)}_k$ (즉, k번째 반복에서 out-of-bag (OOB) 관측치)으로 수행한다.

아래는 본 논문에서 사용하는 몇 가지 개념 정의이다:

---

**정의 1 (무작위 예측기, Random Predictor):**
무작위 예측기는 오직 타겟 확률 분포에만 기반하여 예측을 수행하는 모델이다.

**정의 2 (더미 학습기, Dummy Learner):**
더미 학습기는 학습 샘플에서는 관측된 레이블을 그대로 반환하지만, 새로운 샘플에서는 무작위 예측기를 따르는 학습기이다.

**정의 3 (과적합된 학습기, Overfitted Learner):**
과적합된 학습기 $f_k$ 는 과소적합되지 않았으며, 다음을 만족한다:

$$
\text{Error}_{\text{test}}(f_k) > \text{Error}_{\text{train}}(f_k)
$$

실제로는, 학습 오류(train error)가 테스트 오류(test error)보다 작다는 조건을 완화하기 위해, 두 오류 간 차이가 $\epsilon$ 보다 크도록 설정하는 슬랙 변수(slack variable)를 도입할 수 있다.

**정의 4 (제한 학습기, Limited Learner):**
제한 학습기는 과적합된 학습기이면서, 새로운 샘플에 대해 무작위 예측기보다 더 나은 성능을 보이는 학습기이다.

---

이러한 정의에 따라, 제한 학습기는 더미 학습기보다 일반화 오류(generalization error)가 낮도록 설계된다. 왜냐하면 제한 학습기는 무작위 예측기보다 더 나은 예측 성능을 가지고 있기 때문이다.

현존하는 기법 중 제한 학습기로 간주될 수 있는 유일한 기본 학습기는 **랜덤 포레스트(Random Forest, RF)** 에서 사용하는 결정 트리(Decision Tree, DT)이다. RF에서는 DT의 최대 크기를 제한하지 않으며, 전혀 가지치기(pruning)를 하지 않는다. 즉, 이러한 DT들은 구조적으로 과적합되어 있다\[5]. 따라서 RF에 사용되는 DT는 가능한 한 과적합된 제한 학습기의 특수한 사례라고 할 수 있다.

---

### 4. 최소 과적합 앙상블 (Minimally Overfitted Ensemble)

이 절에서는 **최소 과적합 앙상블(Minimally Overfitted Ensemble, MOE)** 이라는 앙상블 학습 프레임워크를 제안한다. 이 프레임워크는 **최소 과적합 모델(minimal overfitting model)** 과 **제한 학습기(limited learner)** 의 개념을 기반으로 한다. MOE는 약간 과적합된 제한 학습기들을 조합하여 전체 앙상블의 성능을 향상시키는 방식이다.

일반적으로 잘 적합된 모델을 선택하는 방식 중 하나는, 학습 오류(train error)와 테스트 오류(test error)의 차이를 최소화하면서 테스트 오류 자체는 낮게 유지하는 **휴리스틱(heuristic)** 을 정의하는 것이다. 이는 학습 및 테스트 데이터 양쪽 모두에서 과적합을 회피할 수 있도록 한다. 또 다른 방법으로는, 여러 테스트 세트에 대한 평균 오류를 최소화하는 **K-겹 교차검증(K-fold cross-validation)** 등의 기법이 있다\[36, 37]. 그러나 이론적인 오류(error)는 거의 항상 알려져 있지 않기 때문에, 최적의 모델을 찾는 만능 해법(silver bullet)은 존재하지 않는다. 그럼에도 불구하고, 다양한 종류의 오류를 분석함으로써 좋은 해결책을 찾을 수 있다는 점에는 일반적인 동의가 있다.

이러한 관점에서 볼 때, 이진 분류(binary classification)에 대해 최소 과적합을 다음과 같이 정의할 수 있다. 목표는 학습 오류를 중심으로 하면서, 테스트 오류와의 차이를 제어하는 **손실 함수(loss function)** 를 최소화하는 것이다. 이 손실 함수에서 학습 오류가 주요 항이며, 테스트 오류는 학습 오류보다 클 경우에만 과적합 정도를 제어하기 위해 사용된다.

---

**정의 5 (최소 과적합 모델, Minimally Overfitted Model)**
동일한 학습 집합과 테스트 집합에서 학습된 ML 모델들의 집합 $\mathcal{F}$ 가 주어졌을 때, 최소 과적합 모델 $f \in \mathcal{F}$ 는 다음을 만족하는 모델이다:

$$
\underset{f \in \mathcal{F}}{\text{argmin}} \; \mathcal{L}_{\text{mo}}(\lambda, f) = \text{Error}_{\text{train}}(f) + \lambda (\text{Error}_{\text{test}}(f) - \text{Error}_{\text{train}}(f))^2
$$

단, 제약 조건으로

$$
\text{Error}_{\text{test}}(f) > \text{Error}_{\text{train}}(f)
$$

를 만족해야 한다. 여기서 $\lambda \in (0, \infty)$ 는 하이퍼파라미터로, 과적합의 허용 정도를 제어한다.

---

이때 손실 함수 $\mathcal{L}_{\text{mo}}(\lambda, f)$ 는 과적합 손실 함수(overfitting loss function)이며, 테스트 오류가 학습 오류보다 큰 경우에만 적용된다. 주어진 $\lambda$ 값에 대해 이 손실 함수를 최소화하는 모델이 최소 과적합 모델이다. $\lambda$ 값이 작을수록 과적합 모델을 선호하게 되며, $\lambda$ 가 클수록 과적합을 더 강하게 억제한다. 그림 2에서는 다양한 $\lambda$ 값에 따른 손실 함수의 등고선(contour line)을 시각적으로 보여준다.

이러한 최소 과적합 학습기를 기반으로 하는 MOE 프레임워크의 작동 방식을 다음의 의사코드(pseudo-code)로 나타낼 수 있다:

---

**알고리즘 1: MOE 프레임워크**

입력:
학습 집합 $L$, 하이퍼파라미터 집합 $H$, 과적합 제어 파라미터 $\lambda$, 샘플 크기 $n$, 반복 횟수 $m$, 샘플링 방식 $S$, 기본 모델 BaseModel

1. 제한 학습기 집합 $\mathcal{L} \leftarrow \emptyset$
2. for $k = 1$ to $m$:
    2.1. $L_k \leftarrow \text{샘플링}(L, n)$
    2.2. $\text{test} \leftarrow L - L_k$
    2.3. $\mathcal{L}^* \leftarrow \infty$
    2.4. for $h_j \in H$:
      • $l(h_j) \leftarrow \text{모델 학습}(h_j, L_k)$
      • $\text{if } \mathcal{L}_{\text{mo}}(\lambda, l(h_j)) < \mathcal{L}^*$:
        $\mathcal{L}^* \leftarrow \mathcal{L}_{\text{mo}}(\lambda, l(h_j))$
        $L_k \leftarrow l(h_j)$
3. 최종 출력: $F(x) = \text{argmax}_c \sum_{k=1}^{m} L_k(x)$ (다수결)

---

MOE는 정의 5에 따라 학습된 학습기들이 제한 학습기의 조건을 만족함을 보장한다. $\lambda$ 가 적절하게 설정되고, 하이퍼파라미터 풀 $H$ 이 충분히 크면, 어떤 학습기들은 과적합될 것이다. 이들 중 가장 적절한 (과하지 않은) 과적합 모델이 선택된다.

각 학습기의 학습 오류는 해당 부트스트랩 샘플 $L_k$ 에서 계산되고, 테스트 오류는 out-of-bag (OOB) 샘플 $L - L_k$ 에서 계산된다. 이 방식은 각 학습기의 과적합 정도를 정량적으로 평가하는 데 효과적이다. 오차 측정 지표로는 정확도(accuracy) 외에 F1 점수(F1-score), 매튜 상관 계수(Matthews Correlation Coefficient) 등도 사용 가능하지만, 이 중 정확도는 과적합을 부추기는 경향이 있어 주의가 필요하다\[38].

---

이제 샘플링 방법에 대한 설명으로 이어진다. MOE는 Bagging과 유사하므로, 첫 번째 샘플링 방식으로 **부트스트랩(Bootstrap)** 을 채택할 수 있다. 하지만, 단순한 Bootstrap은 최소 과적합 조건을 만족시키기에 충분한 다양성을 제공하지 못할 수 있다. 따라서 **WRAB(Weighted RAndom Bootstrap)** 이라는 새로운 샘플링 방법을 제안한다.

이 방법은 분류 문제에서 클래스 간 샘플 수를 무작위로 불균형하게 조정함으로써 다양성을 증대시키고, 과적합된 결정 경계를 다양하게 생성할 수 있도록 한다. 이는 특히 **안정적인 알고리즘(stable algorithm)** (예: SVM, kNN 등)을 조합할 때 중요하다.

---

### 4.1 가중 랜덤 부트스트랩 (Weighted Random Bootstrap, WRAB)

**WRAB(Weighted Random Bootstrap)** 은 분류 문제에서 클래스 간 샘플 비율을 무작위로 조정함으로써, 클래스 간 불균형을 유도하는 샘플링 절차이다. 이 기법은 각 클래스의 샘플 수를 의도적으로 다르게 설정하여 제한 학습기(limited learner) 간의 **결정 함수(decision function)** 에 다양성을 유도한다.

전체 샘플 수 $n$ 을 갖는 학습 집합 $L = \{(x_i, y_i) : i = 1, 2, ..., n\}$ 를 고려하자. 여기서 $x_i \in \mathbb{R}^r$, $y_i \in \mathbb{N}_m$ (m개의 클래스)이다. WRAB는 총 $S$ 개의 샘플을 생성하며, 각 WRAB 샘플은 다음과 같이 구성된다:

$$
L_b^* = \bigcup_{j=1}^m \{(x_{bi}^*, y_{bi}^*) : i = 1, 2, ..., n_j\}
\quad \text{(식 2)}
$$

여기서 $b = 1, 2, ..., S$, $n_j \in [0, n]$ 는 클래스 $j$ 에 해당하는 샘플 수이다. 이들은 다음 제약 조건을 만족해야 한다:

$$
\sum_{j=1}^m w_j n_j = n, \quad \text{단 } \sum_{j=1}^m w_j = 1 \text{이고 } w_j \sim \mathcal{U}(0, 1)
$$

즉, $w_j$ 는 0에서 1 사이의 균등 분포(uniform distribution)에서 무작위로 추출되며, 각 클래스의 가중치를 구성한다. 주의할 점은, WRAB는 **복원 추출(sampling with replacement)** 방식이므로, 하나의 샘플이 여러 번 나타날 수 있다.

---

이로써 MOE 프레임워크에는 네 가지 주요 하이퍼파라미터(hyperparameter)가 존재하게 된다:

1. 각 제한 학습기(기본 모델)에 사용할 샘플 수
2. 각 샘플의 크기
3. 과적합 제어 파라미터 $\lambda$
4. 샘플링 방법 (Bootstrap 또는 WRAB)

이 중 앞의 두 가지는 기존 생성 앙상블(generative ensemble)에서도 일반적으로 사용되는 하이퍼파라미터이며, 마지막 두 가지는 MOE의 내부 하이퍼파라미터이다.

---

### 5. 실험 (Experiments)

이 장에서는 제안된 MOE 프레임워크의 성능을 여러 대안들과 비교하여 분석한다. 먼저 인공 데이터셋에서 MOE 접근법의 성능과 하이퍼파라미터(hyperparameter)를 분석하고, 이후 다양한 데이터셋을 대상으로 평가를 진행하며, 마지막으로 실험을 통해 얻은 주요 교훈을 정리한다.
실험 재현을 위한 전체 소스코드와 데이터는 다음에서 확인할 수 있다:
📁 [https://github.com/URJCDSLab/moe](https://github.com/URJCDSLab/moe)

---

### 5.1 제어된 시나리오에서의 과적합 하이퍼파라미터 분석

이 예제에서는 다음 조건을 만족하는 3개의 이변량 정규분포(bivariate normal distribution)를 사용하여 이진 분류(binary classification) 문제를 생성하였다:

* 평균(center): (−0.65, −0.1), (2.96, −9.52), (4.05, −6.06)
* 분산: 공통 표준편차(standard deviation) 2
* 도메인: \[−10, 10] × \[−10, 10] ∈ ℝ²
* 클래스 할당: 처음 두 개는 클래스 0, 마지막 하나는 클래스 1
* 각 군집 당 데이터 수: 클래스 0 (총 666개), 클래스 1 (총 333개)

기준 모델로는 **랜덤 포레스트(Random Forest, RF)** 와 **서포트 벡터 머신(SVM)** 을 사용하였다. 두 모델 모두 약 10%의 분류 오류를 보였으며, 10-겹 교차 검증(10-fold cross-validation)으로 평가되었다. 평가 지표는 거짓 양성률(false positives)과 거짓 음성률(false negatives)의 상대 합이다.

기준이 되는 결정 함수(decision function)는 RF 및 SVM을 이용하여 추정되었으며, 그림 3에 시각화되어 있다. MOE 프레임워크에서는 제한 학습기로 가우시안 커널(Gaussian kernel)을 갖는 SVM을 사용하였다. 최소 과적합 함수의 탐색 공간(search space)은 다음과 같이 구성하였다:

* 정규화 상수 C: {1, 10, 100, 1000}
* 커널 계수 γ: {0.01, 0.1, 1, 10}

세 가지 서로 다른 과적합 제어 파라미터 λ 값에 대해 결과를 그림 4에 나타냈다. 각 경우에 대해 제한 학습기 10개를 부트스트랩(Bootstrap) 방식으로 생성하였으며, 샘플 크기는 전체 학습 집합의 10%이다.

* λ가 낮을수록 모델이 극단적으로 과적합되며, 예측 오류가 15%로 증가 (예상보다 50% 나쁨)
* λ가 높을수록 일반화된 결정 경계가 생성되며, 오류율이 10%에 수렴
* λ가 중간일 때, RF와 SVM의 장점을 절충하는 경계를 형성

이 예제에서는 클래스 중심 주변에 데이터 밀도가 높게 분포해 있었기 때문에, λ 값을 낮게 유지하고 Bootstrap을 사용할 경우 학습기 간 다양성이 부족해질 수 있다. 다양성을 확보하려면 λ 값을 높이는 것이 필요하다.

---

### WRAB의 효과 (그림 5)

그림 5는 MOE에서 Bootstrap 대신 WRAB 샘플링을 적용한 경우의 결정 경계를 보여준다. 주요 관찰점은 다음과 같다:

* λ 설정에 따른 결정 경계의 민감도가 낮아짐
* 생성된 결정 경계가 기존 SVM 결과와 현저히 다름 → 즉, 다양성이 증가
* 특히 클래스 경계 근처의 오버랩(overlap) 영역에서 WRAB는 더 다양한 분류기를 생성

그림 6은 λ=1인 경우에 대해 Bootstrap과 WRAB 각각에서 생성된 학습기들의 결정 경계를 보여준다. SVM을 사용할 때 WRAB가 Bootstrap보다 더 다양한 결정 함수를 생성함을 시각적으로 확인할 수 있다.

---

### 표 2: 다양한 조건에서의 오차

| 샘플링 방법 / λ     | 학습 오류 (평균 ± 표준편차) | 테스트 오류 (평균 ± 표준편차) | Lₘₒ 값 (평균 ± 표준편차) |
| -------------- | ----------------- | ------------------ | ----------------- |
| Bootstrap, λ=1 | 0.00 (0.00)       | 0.19 (0.03)        | 0.04 (0.01)       |
| Bootstrap, λ=3 | 0.04 (0.02)       | 0.13 (0.04)        | 0.07 (0.03)       |
| Bootstrap, λ=5 | 0.07 (0.03)       | 0.12 (0.03)        | 0.08 (0.03)       |
| WRAB, λ=1      | 0.02 (0.03)       | 0.20 (0.03)        | 0.05 (0.02)       |
| WRAB, λ=3      | 0.02 (0.03)       | 0.16 (0.04)        | 0.05 (0.02)       |
| WRAB, λ=5      | 0.05 (0.03)       | 0.16 (0.04)        | 0.10 (0.03)       |

이 표는 다음 사실을 보여준다:

* WRAB는 Bootstrap보다 전반적으로 더 높은 테스트 오류를 보이지만, 다양성(diversity)을 확보하는 데 효과적이다.
* 최소 과적합 손실 함수(Lₘₒ)의 값은 λ와 샘플링 방식에 따라 조절 가능하다.

---

### 5.2 MOE 변형들의 성능 분석 (Performance analysis of MOE variations)

이 절에서는 MOE 프레임워크를 다양한 이진 분류(binary classification) 데이터셋을 대상으로 평가한다. 사용된 데이터셋은 다음 세 출처에서 수집되었다:

* UCI 저장소 (UCI repository) \[39]
* 펜실베이니아 머신러닝 벤치마크 (Penn Machine Learning Benchmarks, PMLB) \[40]
* LIBSVM 데이터셋 \[41]

각 데이터셋의 주요 특성은 표 3에 요약되어 있다. 실험에서는 다음과 같은 머신러닝(Machine Learning, ML) 모델들을 비교하였다:

* RF (Random Forest)
* SVM (Radial Basis Function 커널 사용)
* kNN (k-Nearest Neighbor)
* XGBoost
* GB (Gradient Boosting)
* ET (Extra Trees)

이들 기존 모델과 함께, 다음 세 가지 MOE 변형을 비교하였다:

* MOE-DT (기본 학습기로 결정 트리 사용)
* MOE-KNN (기본 학습기로 kNN 사용)
* MOE-SVM (기본 학습기로 SVM 사용)

모델의 예측 성능은 **매튜 상관 계수(Mathews Correlation Coefficient, MCC)** 를 기반으로 평가하였으며, 이 지표는 특히 클래스 불균형이 있는 문제에 적합하다고 널리 알려져 있다\[42]. 해석력을 높이기 위해 MCC 값은 0\~1 사이로 재조정하였다.

모든 모델의 하이퍼파라미터는 **그리드 서치(grid search)** 와 **10-겹 교차검증(10-fold cross-validation)** 을 통해 최적화하였다. 각 모델의 하이퍼파라미터 탐색 공간은 표 4에 정리되어 있다. 명시되지 않은 값은 기본 설정(default value)을 사용하였다.

---

표 5는 25개 데이터셋 각각에 대해 10-겹 교차검증을 수행한 후 얻은 MCC 평균과 표준편차를 요약한 것이다. 주요 결과는 다음과 같다:

* MOE-DT와 MOE-KNN은 전체 25개 중 8개 데이터셋에서 각각 최고 성능을 달성하였다.
* 평균 MCC 기준으로도 MOE-DT가 가장 높은 성능을 보였다.
* 표준편차는 모든 모델에서 유사하므로 평균 비교가 유효하다.

개별 MOE 변형의 성능을 더 정밀하게 비교하기 위해, 전체 데이터셋을 대상으로 다음 두 통계 검정을 수행하였다:

1. **Sign Test**
2. **윌콕슨 순위합 검정(Wilcoxon Signed Rank Test)** \[43]

---

Sign Test에서는 다음을 가정한다:

* 귀무가설(null hypothesis): MOE 변형과 비교 대상 모델의 성능은 동일하다.
* 대립가설(alternative): MOE 변형이 성능 우위에 있다.
* 귀무가설 기각 조건: 승(win) 횟수가 임계값 이상 (α=0.05 기준으로 16회 이상)

그림 7은 각 MOE 변형의 승/무/패 수치를 시각적으로 나타내며, 점선은 유의수준 α={0.05, 0.10}에 따른 임계값을 보여준다.

---

Sign Test 결과:

* MOE-DT는 RF, SVM, kNN, XGBoost, ET를 α=0.05 수준에서 유의하게 능가함.
* MOE-KNN은 kNN에 대해 α=0.05, RF에 대해 α=0.10에서 유의하게 우수함.
* MOE-SVM은 RF, SVM, kNN, ET에 대해 α=0.05, XGBoost, GB에 대해 α=0.10 수준에서 우위 확인.

윌콕슨 검정 결과(α=0.05 기준):

* MOE-DT는 MOE-KNN, MOE-SVM, GB를 제외한 모든 모델보다 유의하게 우수함.
* MOE-KNN은 kNN 외에는 통계적으로 유의한 우위를 보이지 않음.
* MOE-SVM은 단지 kNN에 대해서만 유의한 우위를 보임.

---

요약하면:

* MOE 세 가지 변형 모두 실험에서 양호한 성능을 보였으며, 이는 제한 학습기들이 정확도(accuracy)와 다양성(diversity)을 성공적으로 달성했음을 의미한다.
* MOE-SVM과 MOE-KNN은 거의 모든 사례에서 각각의 단일 모델을 능가하였으며,
* MOE-DT는 동일한 제한 학습기를 사용하는 RF보다도 우수한 성능을 보였다.
* MOE-DT의 상대적 우위는 결정 트리의 과적합 성향과 불안정성 때문일 수 있다.

각 MOE 버전에 대해 선택된 최적 하이퍼파라미터는 표 6에 정리되어 있다.

---

### 5.3 학습된 교훈 (Lessons Learned)

이 절에서는 본 논문에서 제안된 방법이 실제 사례에서 어떤 교훈을 제공하는지 정리한다.

* 생성 앙상블(Generative ensemble)의 가장 큰 강점 중 하나는 각 기본 학습기(base learner)가 서로 다른 **결정 영역(decision region)** 을 생성함으로써 얻는 **다양성(diversity)** 에 있다. 학습 집합 전체를 고르게 커버하면서, 충분한 수의 다양한 샘플을 기반으로 한 학습기를 조합하면 개별 모델보다 더 우수한 결과를 낼 수 있다. 단, 전제 조건은 각 학습기의 정확도(accuracy)가 충분히 높아야 한다는 것이다.

* 학습기의 다양성은 **재표본화 기법(re-sampling techniques)** 을 통해 유도될 수 있다. 그러나 **안정적인 알고리즘(stable algorithm)** 의 경우에는 Bootstrap과 같은 단순한 재표본화 방법만으로는 학습기의 결정 함수(decision function)를 크게 변화시키기 어렵다. 따라서 분류 문제에서는 클래스 레이블을 기준으로 무작위 샘플링을 수행하여 결정 함수를 더 다양하게 만드는 것이 가능하다.

* 본 논문에서는 **WRAB(Weighted Random Bootstrap)** 샘플링 기법을 도입하여, 모든 종류의 최소 과적합 분류기(minimally overfitted classifier)를 MOE 프레임워크에서 학습할 수 있도록 하였다. WRAB와 Bootstrap의 성능 차이를 엄밀히 평가하기 위해 **윌콕슨 검정(Wilcoxon test)** 을 수행하였다.
   결과:
   - 총 25개 데이터셋 중 WRAB와 Bootstrap 각각에서 최고 성능을 기록한 횟수를 비교한 결과,
   - **양측 검정(two-sided test)** 에서 p-value = 0.0092 → 귀무가설(차이 없음) 기각 (95% 신뢰 수준)
   - **단측 검정(one-sided test)** 에서 p-value = 0.0046 → WRAB의 성능이 유의하게 우수함을 입증

---

하이퍼파라미터와 관련하여 다음과 같은 권장 사항을 정리할 수 있다:

* MOE의 기본 설정으로는 다음이 효과적이다:
   • 샘플링 방법: WRAB
   • 학습기 수: 30개
   이 조합은 대부분의 경우에서 좋은 성능을 제공하였다.

* 기본 샘플 비율(sample proportion)은 다음과 같이 설정할 수 있다:
   • MOE-SVM: 0.10
   • MOE-kNN 및 MOE-DT: 0.50

* 과적합 제어 파라미터 λ는 다음을 권장한다:
   • MOE-DT: λ = 1
   • MOE-SVM 및 MOE-kNN: λ = 5

* 일반적인 권장 전략:
   먼저 학습기 수와 샘플 비율을 조정해보고, 이후 λ나 샘플링 방식을 조정하는 것이 좋다.

---

최소 과적합 제한 학습기(minimally overfitted limited learner)는 학습 샘플을 충분히 커버한다는 조건 하에서, 앙상블 내에서 매우 좋은 성능을 발휘할 수 있다.
재표본화에 의해 생성된 변동은 **잘 적합된 모델(well-fitted learner)** 보다는 **최소 과적합 모델** 에서 결정 함수의 다양성에 더 큰 영향을 준다.
또한 MOE에서는 RF 등 기존 앙상블보다 더 적은 샘플 크기로도 높은 다양성을 달성할 수 있기 때문에, 학습기 간 중복 없이 전체 데이터를 효율적으로 커버할 수 있다.

---

### 6. 결론 및 향후 연구 (Conclusions and Future Work)

본 논문에서는 **제한 학습기(limited learner)** 의 개념을 새롭게 도입하였다. 제한 학습기란, 훈련 데이터에 과적합(overfitting)되지만, 무작위 예측기(random predictor)보다 일반화 성능이 우수한 학습기를 말한다.

이 개념을 기반으로 하여, **MOE(Minimally Overfitted Ensemble)** 라는 일반화된 재표본화 기반(Resampling-based) 머신러닝(Machine Learning, ML) 프레임워크를 제안하였다. 이 프레임워크는 **안정적인(stable)** 알고리즘과 **불안정한(unstable)** 알고리즘 모두에서 사용할 수 있으며, 기존 앙상블에서 안정적인 모델이 가지는 성능 저하의 한계를 극복하도록 설계되었다.

MOE의 핵심 아이디어는, 각 샘플에 대해 하이퍼파라미터 탐색(hyperparameter search)을 수행하고, **최소 과적합(minimum overfitting)** 기준에 따라 가장 적합한 학습기를 선택하는 것이다. 이렇게 선택된 결과는 **최소 과적합 학습기(minimally overfitted learner)** 로, 이는 제한 학습기의 특수한 사례에 해당한다.

또한, 각 기본 학습기를 위한 학습 샘플을 생성하기 위해, 새로운 샘플링 방식인 **WRAB(Weighted RAndom Bootstrap)** 을 도입하였다. WRAB는 기존의 Bootstrap 위에 추가적인 층(layer)을 형성하여 클래스 간 균형을 의도적으로 무너뜨리는 방식으로 작동한다. 이로 인해, 특히 안정적인 모델을 사용할 경우에도 학습기 간 **결정 경계(decision boundary)** 의 다양성을 확보할 수 있다.

최종적으로 생성된 제한 학습기들은 **다수결 투표(majority-voting rule)** 방식으로 결합되어 앙상블 예측을 수행한다.

---

본 프레임워크의 성능은 총 18개의 실제 이진 분류 데이터셋을 대상으로 다음 세 가지 기본 학습기 모델에서 평가되었다:

* SVM (Support Vector Machine)
* DT (Decision Tree)
* kNN (k-Nearest Neighbor)

그 결과 MOE는 각각의 단일 모델 단독 실행보다 더 나은 성능을 보였다. 특히 MOE-DT는 전반적으로 가장 우수한 성능을 기록하였다.

하이퍼파라미터 분석 결과에 따르면, **기본 학습기의 불안정성(instability)** 과 **과적합 경향** 은 MOE의 전체 성능에 긍정적 영향을 미친다. 안정적인 모델(SVM 등)을 사용하는 경우에도, WRAB는 모델 간 다양성을 확보하는 데 효과적이었으며, 단일 SVM을 능가하는 성능을 달성하였다.

또한, MOE는 기존 제한 학습기 기반 앙상블인 **랜덤 포레스트(Random Forest)** 보다도 약간 더 나은 성능을 보였다.

---

하지만 MOE에서 정의된 최소 과적합 모델을 찾기 위해서는 다수의 후보 모델 집합이 필요하며, 이로 인해 **학습 시간(training time)** 이 증가한다. 이는 특히 대규모 데이터셋에 대한 실험을 제한하는 요인이 된다.

MOE의 학습 시간은 다음 세 요소에 의해 크게 영향을 받는다:

1. 각 샘플에 대해 수행되는 하이퍼파라미터 탐색의 범위
2. 복잡한 모델(SVM 등)의 훈련 비용
3. 제한 학습기 개수(m)의 크기

---

따라서 향후 연구 방향은 다음과 같다:

* 최소 과적합 학습기를 선택하는 과정에서 탐색해야 하는 학습기 집합을 줄이는 방안

* WRAB 샘플링이 안정적인 모델에서도 다양성을 확보할 수 있지만, 일부 경우에는 불충분할 수 있으므로,
   • 샘플링 방법 또는 λ(과적합 제어 파라미터)를 문제에 맞게 동적으로 조정하는 **상황 인지(context-aware)** 전략이 필요
   • 예: 복잡한 영역에는 더 많은 샘플을 생성하고, 단순한 영역에서는 샘플 수를 줄이거나 더 안정적인 모델 사용

* 데이터 불균형(unbalanced data)에 대한 최신 기법들을 MOE에 통합하는 방안 연구

* 마지막으로, MOE 프레임워크를 다중 클래스 분류(multiclass classification)와 회귀(regression) 문제로 확장하는 것도 중요한 연구 방향이 될 것이다. 이 과정에서는 최소 과적합 모델의 정의와 WRAB의 구조를 해당 문제 유형에 맞게 재설계해야 한다.

---

이상으로 본 논문의 결론 및 향후 연구 방향을 마친다.
